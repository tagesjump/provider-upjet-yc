// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/v2/apis/common/v1"
	v2 "github.com/crossplane/crossplane-runtime/v2/apis/common/v2"
)

type AccessControlImprovementsInitParameters struct {

	// (Boolean) Sets whether SELECT * FROM information_schema.<table> requires any grants and can be executed by any user. If set to true, then this query requires GRANT SELECT ON information_schema.<table>, just as for ordinary tables.
	// Sets whether `SELECT * FROM information_schema.<table>` requires any grants and can be executed by any user. If set to true, then this query requires `GRANT SELECT ON information_schema.<table>`, just as for ordinary tables.
	SelectFromInformationSchemaRequiresGrant *bool `json:"selectFromInformationSchemaRequiresGrant,omitempty" tf:"select_from_information_schema_requires_grant,omitempty"`

	// system tables.
	// Sets whether `SELECT * FROM system.<table>` requires any grants and can be executed by any user. If set to true then this query requires `GRANT SELECT ON system.<table>` just as for non-system tables.
	SelectFromSystemDBRequiresGrant *bool `json:"selectFromSystemDbRequiresGrant,omitempty" tf:"select_from_system_db_requires_grant,omitempty"`
}

type AccessControlImprovementsObservation struct {

	// (Boolean) Sets whether SELECT * FROM information_schema.<table> requires any grants and can be executed by any user. If set to true, then this query requires GRANT SELECT ON information_schema.<table>, just as for ordinary tables.
	// Sets whether `SELECT * FROM information_schema.<table>` requires any grants and can be executed by any user. If set to true, then this query requires `GRANT SELECT ON information_schema.<table>`, just as for ordinary tables.
	SelectFromInformationSchemaRequiresGrant *bool `json:"selectFromInformationSchemaRequiresGrant,omitempty" tf:"select_from_information_schema_requires_grant,omitempty"`

	// system tables.
	// Sets whether `SELECT * FROM system.<table>` requires any grants and can be executed by any user. If set to true then this query requires `GRANT SELECT ON system.<table>` just as for non-system tables.
	SelectFromSystemDBRequiresGrant *bool `json:"selectFromSystemDbRequiresGrant,omitempty" tf:"select_from_system_db_requires_grant,omitempty"`
}

type AccessControlImprovementsParameters struct {

	// (Boolean) Sets whether SELECT * FROM information_schema.<table> requires any grants and can be executed by any user. If set to true, then this query requires GRANT SELECT ON information_schema.<table>, just as for ordinary tables.
	// Sets whether `SELECT * FROM information_schema.<table>` requires any grants and can be executed by any user. If set to true, then this query requires `GRANT SELECT ON information_schema.<table>`, just as for ordinary tables.
	// +kubebuilder:validation:Optional
	SelectFromInformationSchemaRequiresGrant *bool `json:"selectFromInformationSchemaRequiresGrant,omitempty" tf:"select_from_information_schema_requires_grant,omitempty"`

	// system tables.
	// Sets whether `SELECT * FROM system.<table>` requires any grants and can be executed by any user. If set to true then this query requires `GRANT SELECT ON system.<table>` just as for non-system tables.
	// +kubebuilder:validation:Optional
	SelectFromSystemDBRequiresGrant *bool `json:"selectFromSystemDbRequiresGrant,omitempty" tf:"select_from_system_db_requires_grant,omitempty"`
}

type ClickhouseClusterV2AccessInitParameters struct {

	// (Boolean) Allow access for DataLens.
	// Allow access for DataLens.
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// (Boolean) Allow access for DataTransfer.
	// Allow access for DataTransfer.
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// (Boolean) Allow access for Yandex.Metrika.
	// Allow access for Yandex.Metrika.
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// (Boolean) Allow access for Serverless.
	// Allow access for Serverless.
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// (Boolean) Allow access for Web SQL.
	// Allow access for Web SQL.
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// (Boolean) Allow access for YandexQuery.
	// Allow access for YandexQuery.
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type ClickhouseClusterV2AccessObservation struct {

	// (Boolean) Allow access for DataLens.
	// Allow access for DataLens.
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// (Boolean) Allow access for DataTransfer.
	// Allow access for DataTransfer.
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// (Boolean) Allow access for Yandex.Metrika.
	// Allow access for Yandex.Metrika.
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// (Boolean) Allow access for Serverless.
	// Allow access for Serverless.
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// (Boolean) Allow access for Web SQL.
	// Allow access for Web SQL.
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// (Boolean) Allow access for YandexQuery.
	// Allow access for YandexQuery.
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type ClickhouseClusterV2AccessParameters struct {

	// (Boolean) Allow access for DataLens.
	// Allow access for DataLens.
	// +kubebuilder:validation:Optional
	DataLens *bool `json:"dataLens,omitempty" tf:"data_lens,omitempty"`

	// (Boolean) Allow access for DataTransfer.
	// Allow access for DataTransfer.
	// +kubebuilder:validation:Optional
	DataTransfer *bool `json:"dataTransfer,omitempty" tf:"data_transfer,omitempty"`

	// (Boolean) Allow access for Yandex.Metrika.
	// Allow access for Yandex.Metrika.
	// +kubebuilder:validation:Optional
	Metrika *bool `json:"metrika,omitempty" tf:"metrika,omitempty"`

	// (Boolean) Allow access for Serverless.
	// Allow access for Serverless.
	// +kubebuilder:validation:Optional
	Serverless *bool `json:"serverless,omitempty" tf:"serverless,omitempty"`

	// (Boolean) Allow access for Web SQL.
	// Allow access for Web SQL.
	// +kubebuilder:validation:Optional
	WebSQL *bool `json:"webSql,omitempty" tf:"web_sql,omitempty"`

	// (Boolean) Allow access for YandexQuery.
	// Allow access for YandexQuery.
	// +kubebuilder:validation:Optional
	YandexQuery *bool `json:"yandexQuery,omitempty" tf:"yandex_query,omitempty"`
}

type ClickhouseClusterV2BackupWindowStartInitParameters struct {

	// (Number) The hour at which backup will be started (UTC).
	// The hour at which backup will be started (UTC).
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// (Number) The minute at which backup will be started (UTC).
	// The minute at which backup will be started (UTC).
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type ClickhouseClusterV2BackupWindowStartObservation struct {

	// (Number) The hour at which backup will be started (UTC).
	// The hour at which backup will be started (UTC).
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// (Number) The minute at which backup will be started (UTC).
	// The minute at which backup will be started (UTC).
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type ClickhouseClusterV2BackupWindowStartParameters struct {

	// (Number) The hour at which backup will be started (UTC).
	// The hour at which backup will be started (UTC).
	// +kubebuilder:validation:Optional
	Hours *float64 `json:"hours,omitempty" tf:"hours,omitempty"`

	// (Number) The minute at which backup will be started (UTC).
	// The minute at which backup will be started (UTC).
	// +kubebuilder:validation:Optional
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`
}

type ClickhouseClusterV2ClickhouseInitParameters struct {

	// (Attributes) Configuration of the ClickHouse subcluster. (see below for nested schema)
	Config *ClickhouseConfigInitParameters `json:"config,omitempty" tf:"config,omitempty"`

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	Resources *ClickhouseResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ClickhouseClusterV2ClickhouseObservation struct {

	// (Attributes) Configuration of the ClickHouse subcluster. (see below for nested schema)
	Config *ClickhouseConfigObservation `json:"config,omitempty" tf:"config,omitempty"`

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	Resources *ClickhouseResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ClickhouseClusterV2ClickhouseParameters struct {

	// (Attributes) Configuration of the ClickHouse subcluster. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Config *ClickhouseConfigParameters `json:"config,omitempty" tf:"config,omitempty"`

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Resources *ClickhouseResourcesParameters `json:"resources" tf:"resources,omitempty"`
}

type ClickhouseClusterV2CloudStorageInitParameters struct {

	// (Boolean) Enables temporary storage in the cluster repository of data requested from the object repository.
	// Enables temporary storage in the cluster repository of data requested from the object repository.
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// (Number) Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// (Boolean) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// (Number) Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// (Boolean) Disables merging of data parts in Yandex Object Storage.
	// Disables merging of data parts in `Yandex Object Storage`.
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type ClickhouseClusterV2CloudStorageObservation struct {

	// (Boolean) Enables temporary storage in the cluster repository of data requested from the object repository.
	// Enables temporary storage in the cluster repository of data requested from the object repository.
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// (Number) Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// (Boolean) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// (Number) Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// (Boolean) Disables merging of data parts in Yandex Object Storage.
	// Disables merging of data parts in `Yandex Object Storage`.
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type ClickhouseClusterV2CloudStorageParameters struct {

	// (Boolean) Enables temporary storage in the cluster repository of data requested from the object repository.
	// Enables temporary storage in the cluster repository of data requested from the object repository.
	// +kubebuilder:validation:Optional
	DataCacheEnabled *bool `json:"dataCacheEnabled,omitempty" tf:"data_cache_enabled,omitempty"`

	// (Number) Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
	// +kubebuilder:validation:Optional
	DataCacheMaxSize *float64 `json:"dataCacheMaxSize,omitempty" tf:"data_cache_max_size,omitempty"`

	// (Boolean) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either true or false.
	// Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`

	// (Number) Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
	// +kubebuilder:validation:Optional
	MoveFactor *float64 `json:"moveFactor,omitempty" tf:"move_factor,omitempty"`

	// (Boolean) Disables merging of data parts in Yandex Object Storage.
	// Disables merging of data parts in `Yandex Object Storage`.
	// +kubebuilder:validation:Optional
	PreferNotToMerge *bool `json:"preferNotToMerge,omitempty" tf:"prefer_not_to_merge,omitempty"`
}

type ClickhouseClusterV2FormatSchemaInitParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the format schema.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the format schema.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type ClickhouseClusterV2FormatSchemaObservation struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the format schema.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the format schema.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type ClickhouseClusterV2FormatSchemaParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the format schema.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the format schema.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// +kubebuilder:validation:Optional
	URI *string `json:"uri" tf:"uri,omitempty"`
}

type ClickhouseClusterV2InitParameters struct {

	// (Attributes) Access policy to the ClickHouse cluster. (see below for nested schema)
	Access *ClickhouseClusterV2AccessInitParameters `json:"access,omitempty" tf:"access,omitempty"`

	// (String, Sensitive) A password used to authorize as user admin when sql_user_management enabled.
	// A password used to authorize as user `admin` when `sql_user_management` enabled.
	AdminPasswordSecretRef *v1.LocalSecretKeySelector `json:"adminPasswordSecretRef,omitempty" tf:"-"`

	// (Number) The period in days during which backups are stored.
	// The period in days during which backups are stored.
	BackupRetainPeriodDays *float64 `json:"backupRetainPeriodDays,omitempty" tf:"backup_retain_period_days,omitempty"`

	// (Attributes) Time to start the daily backup, in the UTC timezone. (see below for nested schema)
	BackupWindowStart *ClickhouseClusterV2BackupWindowStartInitParameters `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// (Attributes) Configuration of the ClickHouse subcluster. (see below for nested schema)
	Clickhouse *ClickhouseClusterV2ClickhouseInitParameters `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// (Attributes) Cloud Storage settings. (see below for nested schema)
	CloudStorage *ClickhouseClusterV2CloudStorageInitParameters `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	// (Boolean) Whether to copy schema on new ClickHouse hosts.
	// Whether to copy schema on new ClickHouse hosts.
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// (Boolean) The true value means that resource is protected from accidental deletion.
	// The `true` value means that resource is protected from accidental deletion.
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// (String) The resource description.
	// The resource description.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) ID of the KMS key for cluster disk encryption.
	// ID of the KMS key for cluster disk encryption.
	DiskEncryptionKeyID *string `json:"diskEncryptionKeyId,omitempty" tf:"disk_encryption_key_id,omitempty"`

	// (Boolean) Whether to use ClickHouse Keeper as a coordination system.
	// Whether to use ClickHouse Keeper as a coordination system.
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// (String) Deployment environment of the ClickHouse cluster.
	// Deployment environment of the ClickHouse cluster.
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// id is used.
	// The folder identifier that resource belongs to. If it is not provided, the default provider `folder-id` is used.
	// +crossplane:generate:reference:type=github.com/tagesjump/provider-upjet-yc/apis/cluster/resourcemanager/v1alpha1.Folder
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// Reference to a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDRef *v1.NamespacedReference `json:"folderIdRef,omitempty" tf:"-"`

	// Selector for a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDSelector *v1.NamespacedSelector `json:"folderIdSelector,omitempty" tf:"-"`

	// (Block Set) A set of protobuf or capnproto format schemas. (see below for nested schema)
	// A set of `protobuf` or `capnproto` format schemas.
	FormatSchema []ClickhouseClusterV2FormatSchemaInitParameters `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// (Attributes Map) A host configuration of the ClickHouse cluster. (see below for nested schema)
	Hosts map[string]HostsInitParameters `json:"hosts,omitempty" tf:"hosts,omitempty"`

	// (Map of String) A set of key/value label pairs which assigned to resource.
	// A set of key/value label pairs which assigned to resource.
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// (Block Set) A group of machine learning models. (see below for nested schema)
	// A group of machine learning models.
	MLModel []ClickhouseClusterV2MLModelInitParameters `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The VPC Network ID of subnets which resource attached to.
	// The `VPC Network ID` of subnets which resource attached to.
	// +crossplane:generate:reference:type=github.com/tagesjump/provider-upjet-yc/apis/namespaced/vpc/v1alpha1.Network
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/v2/pkg/resource.ExtractResourceID()
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// Reference to a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDRef *v1.NamespacedReference `json:"networkIdRef,omitempty" tf:"-"`

	// Selector for a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDSelector *v1.NamespacedSelector `json:"networkIdSelector,omitempty" tf:"-"`

	// (Boolean) Grants admin user database management permission.
	// Grants `admin` user database management permission.
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// (Boolean) Enables admin user with user management permission.
	// Enables `admin` user with user management permission.
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// (Set of String) The list of security groups applied to resource or their components.
	// The list of security groups applied to resource or their components.
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// (String) Service account which linked to the resource.
	// [Service account](https://yandex.cloud/docs/iam/concepts/users/service-accounts) which linked to the resource.
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	// (Block List) A group of clickhouse shards. (see below for nested schema)
	// A group of clickhouse shards.
	ShardGroup []ClickhouseClusterV2ShardGroupInitParameters `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// (Attributes Map) A shards of the ClickHouse cluster. (see below for nested schema)
	Shards map[string]ShardsInitParameters `json:"shards,omitempty" tf:"shards,omitempty"`

	// (Attributes) (see below for nested schema)
	Timeouts *TimeoutsInitParameters `json:"timeouts,omitempty" tf:"timeouts,omitempty"`

	// (String) Version of the ClickHouse server software.
	// Version of the ClickHouse server software.
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// (Attributes) Configuration of the ZooKeeper subcluster. (see below for nested schema)
	Zookeeper *ClickhouseClusterV2ZookeeperInitParameters `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseClusterV2MLModelInitParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the ml model.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the model.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Model file URL. You can only use models stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type ClickhouseClusterV2MLModelObservation struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the ml model.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the model.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Model file URL. You can only use models stored in Yandex Object Storage.
	URI *string `json:"uri,omitempty" tf:"uri,omitempty"`
}

type ClickhouseClusterV2MLModelParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the ml model.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of the model.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// (String) Format schema file URL. You can only use format schemas stored in Yandex Object Storage.
	// Model file URL. You can only use models stored in Yandex Object Storage.
	// +kubebuilder:validation:Optional
	URI *string `json:"uri" tf:"uri,omitempty"`
}

type ClickhouseClusterV2MaintenanceWindowInitParameters struct {

	// (String) Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	// Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// 24) for maintenance window if window type is weekly.
	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type ClickhouseClusterV2MaintenanceWindowObservation struct {

	// (String) Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	// Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// 24) for maintenance window if window type is weekly.
	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type ClickhouseClusterV2MaintenanceWindowParameters struct {

	// (String) Day of week for maintenance window if window type is weekly. Possible values: MON, TUE, WED, THU, FRI, SAT, SUN.
	// Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
	// +kubebuilder:validation:Optional
	Day *string `json:"day,omitempty" tf:"day,omitempty"`

	// 24) for maintenance window if window type is weekly.
	// Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
	// +kubebuilder:validation:Optional
	Hour *float64 `json:"hour,omitempty" tf:"hour,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type ClickhouseClusterV2Observation struct {

	// (Attributes) Access policy to the ClickHouse cluster. (see below for nested schema)
	Access *ClickhouseClusterV2AccessObservation `json:"access,omitempty" tf:"access,omitempty"`

	// (Number) The period in days during which backups are stored.
	// The period in days during which backups are stored.
	BackupRetainPeriodDays *float64 `json:"backupRetainPeriodDays,omitempty" tf:"backup_retain_period_days,omitempty"`

	// (Attributes) Time to start the daily backup, in the UTC timezone. (see below for nested schema)
	BackupWindowStart *ClickhouseClusterV2BackupWindowStartObservation `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// (Attributes) Configuration of the ClickHouse subcluster. (see below for nested schema)
	Clickhouse *ClickhouseClusterV2ClickhouseObservation `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// (Attributes) Cloud Storage settings. (see below for nested schema)
	CloudStorage *ClickhouseClusterV2CloudStorageObservation `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	// (String) ID of the ClickHouse cluster. This ID is assigned by MDB at creation time.
	// ID of the ClickHouse cluster. This ID is assigned by MDB at creation time.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// (Boolean) Whether to copy schema on new ClickHouse hosts.
	// Whether to copy schema on new ClickHouse hosts.
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// (String) The creation timestamp of the resource.
	// The creation timestamp of the resource.
	CreatedAt *string `json:"createdAt,omitempty" tf:"created_at,omitempty"`

	// (Boolean) The true value means that resource is protected from accidental deletion.
	// The `true` value means that resource is protected from accidental deletion.
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// (String) The resource description.
	// The resource description.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) ID of the KMS key for cluster disk encryption.
	// ID of the KMS key for cluster disk encryption.
	DiskEncryptionKeyID *string `json:"diskEncryptionKeyId,omitempty" tf:"disk_encryption_key_id,omitempty"`

	// (Boolean) Whether to use ClickHouse Keeper as a coordination system.
	// Whether to use ClickHouse Keeper as a coordination system.
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// (String) Deployment environment of the ClickHouse cluster.
	// Deployment environment of the ClickHouse cluster.
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// id is used.
	// The folder identifier that resource belongs to. If it is not provided, the default provider `folder-id` is used.
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// (Block Set) A set of protobuf or capnproto format schemas. (see below for nested schema)
	// A set of `protobuf` or `capnproto` format schemas.
	FormatSchema []ClickhouseClusterV2FormatSchemaObservation `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// (Attributes Map) A host configuration of the ClickHouse cluster. (see below for nested schema)
	Hosts map[string]HostsObservation `json:"hosts,omitempty" tf:"hosts,omitempty"`

	// (String) The resource identifier.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// (Map of String) A set of key/value label pairs which assigned to resource.
	// A set of key/value label pairs which assigned to resource.
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// (Block Set) A group of machine learning models. (see below for nested schema)
	// A group of machine learning models.
	MLModel []ClickhouseClusterV2MLModelObservation `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	// (Block, Optional) Maintenance window settings. (see below for nested schema)
	// Maintenance window settings.
	MaintenanceWindow []ClickhouseClusterV2MaintenanceWindowObservation `json:"maintenanceWindow,omitempty" tf:"maintenance_window,omitempty"`

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The VPC Network ID of subnets which resource attached to.
	// The `VPC Network ID` of subnets which resource attached to.
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// (Boolean) Grants admin user database management permission.
	// Grants `admin` user database management permission.
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// (Boolean) Enables admin user with user management permission.
	// Enables `admin` user with user management permission.
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// (Set of String) The list of security groups applied to resource or their components.
	// The list of security groups applied to resource or their components.
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// (String) Service account which linked to the resource.
	// [Service account](https://yandex.cloud/docs/iam/concepts/users/service-accounts) which linked to the resource.
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	// (Block List) A group of clickhouse shards. (see below for nested schema)
	// A group of clickhouse shards.
	ShardGroup []ClickhouseClusterV2ShardGroupObservation `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// (Attributes Map) A shards of the ClickHouse cluster. (see below for nested schema)
	Shards map[string]ShardsObservation `json:"shards,omitempty" tf:"shards,omitempty"`

	// (Attributes) (see below for nested schema)
	Timeouts *TimeoutsObservation `json:"timeouts,omitempty" tf:"timeouts,omitempty"`

	// (String) Version of the ClickHouse server software.
	// Version of the ClickHouse server software.
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// (Attributes) Configuration of the ZooKeeper subcluster. (see below for nested schema)
	Zookeeper *ClickhouseClusterV2ZookeeperObservation `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseClusterV2Parameters struct {

	// (Attributes) Access policy to the ClickHouse cluster. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Access *ClickhouseClusterV2AccessParameters `json:"access,omitempty" tf:"access,omitempty"`

	// (String, Sensitive) A password used to authorize as user admin when sql_user_management enabled.
	// A password used to authorize as user `admin` when `sql_user_management` enabled.
	// +kubebuilder:validation:Optional
	AdminPasswordSecretRef *v1.LocalSecretKeySelector `json:"adminPasswordSecretRef,omitempty" tf:"-"`

	// (Number) The period in days during which backups are stored.
	// The period in days during which backups are stored.
	// +kubebuilder:validation:Optional
	BackupRetainPeriodDays *float64 `json:"backupRetainPeriodDays,omitempty" tf:"backup_retain_period_days,omitempty"`

	// (Attributes) Time to start the daily backup, in the UTC timezone. (see below for nested schema)
	// +kubebuilder:validation:Optional
	BackupWindowStart *ClickhouseClusterV2BackupWindowStartParameters `json:"backupWindowStart,omitempty" tf:"backup_window_start,omitempty"`

	// (Attributes) Configuration of the ClickHouse subcluster. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Clickhouse *ClickhouseClusterV2ClickhouseParameters `json:"clickhouse,omitempty" tf:"clickhouse,omitempty"`

	// (Attributes) Cloud Storage settings. (see below for nested schema)
	// +kubebuilder:validation:Optional
	CloudStorage *ClickhouseClusterV2CloudStorageParameters `json:"cloudStorage,omitempty" tf:"cloud_storage,omitempty"`

	// (Boolean) Whether to copy schema on new ClickHouse hosts.
	// Whether to copy schema on new ClickHouse hosts.
	// +kubebuilder:validation:Optional
	CopySchemaOnNewHosts *bool `json:"copySchemaOnNewHosts,omitempty" tf:"copy_schema_on_new_hosts,omitempty"`

	// (Boolean) The true value means that resource is protected from accidental deletion.
	// The `true` value means that resource is protected from accidental deletion.
	// +kubebuilder:validation:Optional
	DeletionProtection *bool `json:"deletionProtection,omitempty" tf:"deletion_protection,omitempty"`

	// (String) The resource description.
	// The resource description.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) ID of the KMS key for cluster disk encryption.
	// ID of the KMS key for cluster disk encryption.
	// +kubebuilder:validation:Optional
	DiskEncryptionKeyID *string `json:"diskEncryptionKeyId,omitempty" tf:"disk_encryption_key_id,omitempty"`

	// (Boolean) Whether to use ClickHouse Keeper as a coordination system.
	// Whether to use ClickHouse Keeper as a coordination system.
	// +kubebuilder:validation:Optional
	EmbeddedKeeper *bool `json:"embeddedKeeper,omitempty" tf:"embedded_keeper,omitempty"`

	// (String) Deployment environment of the ClickHouse cluster.
	// Deployment environment of the ClickHouse cluster.
	// +kubebuilder:validation:Optional
	Environment *string `json:"environment,omitempty" tf:"environment,omitempty"`

	// id is used.
	// The folder identifier that resource belongs to. If it is not provided, the default provider `folder-id` is used.
	// +crossplane:generate:reference:type=github.com/tagesjump/provider-upjet-yc/apis/cluster/resourcemanager/v1alpha1.Folder
	// +kubebuilder:validation:Optional
	FolderID *string `json:"folderId,omitempty" tf:"folder_id,omitempty"`

	// Reference to a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDRef *v1.NamespacedReference `json:"folderIdRef,omitempty" tf:"-"`

	// Selector for a Folder in resourcemanager to populate folderId.
	// +kubebuilder:validation:Optional
	FolderIDSelector *v1.NamespacedSelector `json:"folderIdSelector,omitempty" tf:"-"`

	// (Block Set) A set of protobuf or capnproto format schemas. (see below for nested schema)
	// A set of `protobuf` or `capnproto` format schemas.
	// +kubebuilder:validation:Optional
	FormatSchema []ClickhouseClusterV2FormatSchemaParameters `json:"formatSchema,omitempty" tf:"format_schema,omitempty"`

	// (Attributes Map) A host configuration of the ClickHouse cluster. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Hosts map[string]HostsParameters `json:"hosts,omitempty" tf:"hosts,omitempty"`

	// (Map of String) A set of key/value label pairs which assigned to resource.
	// A set of key/value label pairs which assigned to resource.
	// +kubebuilder:validation:Optional
	// +mapType=granular
	Labels map[string]*string `json:"labels,omitempty" tf:"labels,omitempty"`

	// (Block Set) A group of machine learning models. (see below for nested schema)
	// A group of machine learning models.
	// +kubebuilder:validation:Optional
	MLModel []ClickhouseClusterV2MLModelParameters `json:"mlModel,omitempty" tf:"ml_model,omitempty"`

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The VPC Network ID of subnets which resource attached to.
	// The `VPC Network ID` of subnets which resource attached to.
	// +crossplane:generate:reference:type=github.com/tagesjump/provider-upjet-yc/apis/namespaced/vpc/v1alpha1.Network
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/v2/pkg/resource.ExtractResourceID()
	// +kubebuilder:validation:Optional
	NetworkID *string `json:"networkId,omitempty" tf:"network_id,omitempty"`

	// Reference to a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDRef *v1.NamespacedReference `json:"networkIdRef,omitempty" tf:"-"`

	// Selector for a Network in vpc to populate networkId.
	// +kubebuilder:validation:Optional
	NetworkIDSelector *v1.NamespacedSelector `json:"networkIdSelector,omitempty" tf:"-"`

	// (Boolean) Grants admin user database management permission.
	// Grants `admin` user database management permission.
	// +kubebuilder:validation:Optional
	SQLDatabaseManagement *bool `json:"sqlDatabaseManagement,omitempty" tf:"sql_database_management,omitempty"`

	// (Boolean) Enables admin user with user management permission.
	// Enables `admin` user with user management permission.
	// +kubebuilder:validation:Optional
	SQLUserManagement *bool `json:"sqlUserManagement,omitempty" tf:"sql_user_management,omitempty"`

	// (Set of String) The list of security groups applied to resource or their components.
	// The list of security groups applied to resource or their components.
	// +kubebuilder:validation:Optional
	// +listType=set
	SecurityGroupIds []*string `json:"securityGroupIds,omitempty" tf:"security_group_ids,omitempty"`

	// (String) Service account which linked to the resource.
	// [Service account](https://yandex.cloud/docs/iam/concepts/users/service-accounts) which linked to the resource.
	// +kubebuilder:validation:Optional
	ServiceAccountID *string `json:"serviceAccountId,omitempty" tf:"service_account_id,omitempty"`

	// (Block List) A group of clickhouse shards. (see below for nested schema)
	// A group of clickhouse shards.
	// +kubebuilder:validation:Optional
	ShardGroup []ClickhouseClusterV2ShardGroupParameters `json:"shardGroup,omitempty" tf:"shard_group,omitempty"`

	// (Attributes Map) A shards of the ClickHouse cluster. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Shards map[string]ShardsParameters `json:"shards,omitempty" tf:"shards,omitempty"`

	// (Attributes) (see below for nested schema)
	// +kubebuilder:validation:Optional
	Timeouts *TimeoutsParameters `json:"timeouts,omitempty" tf:"timeouts,omitempty"`

	// (String) Version of the ClickHouse server software.
	// Version of the ClickHouse server software.
	// +kubebuilder:validation:Optional
	Version *string `json:"version,omitempty" tf:"version,omitempty"`

	// (Attributes) Configuration of the ZooKeeper subcluster. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Zookeeper *ClickhouseClusterV2ZookeeperParameters `json:"zookeeper,omitempty" tf:"zookeeper,omitempty"`
}

type ClickhouseClusterV2ShardGroupInitParameters struct {

	// (String) The resource description.
	// Description of the shard group.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the shard group, used as cluster name in Distributed tables.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (List of String) List of shards names that belong to the shard group.
	// List of shards names that belong to the shard group.
	ShardNames []*string `json:"shardNames,omitempty" tf:"shard_names,omitempty"`
}

type ClickhouseClusterV2ShardGroupObservation struct {

	// (String) The resource description.
	// Description of the shard group.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the shard group, used as cluster name in Distributed tables.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (List of String) List of shards names that belong to the shard group.
	// List of shards names that belong to the shard group.
	ShardNames []*string `json:"shardNames,omitempty" tf:"shard_names,omitempty"`
}

type ClickhouseClusterV2ShardGroupParameters struct {

	// (String) The resource description.
	// Description of the shard group.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// The name of the shard group, used as cluster name in Distributed tables.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (List of String) List of shards names that belong to the shard group.
	// List of shards names that belong to the shard group.
	// +kubebuilder:validation:Optional
	ShardNames []*string `json:"shardNames" tf:"shard_names,omitempty"`
}

type ClickhouseClusterV2ZookeeperInitParameters struct {

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	Resources *ClickhouseClusterV2ZookeeperResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ClickhouseClusterV2ZookeeperObservation struct {

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	Resources *ClickhouseClusterV2ZookeeperResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`
}

type ClickhouseClusterV2ZookeeperParameters struct {

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Resources *ClickhouseClusterV2ZookeeperResourcesParameters `json:"resources" tf:"resources,omitempty"`
}

type ClickhouseClusterV2ZookeeperResourcesInitParameters struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ClickhouseClusterV2ZookeeperResourcesObservation struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ClickhouseClusterV2ZookeeperResourcesParameters struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId" tf:"resource_preset_id,omitempty"`
}

type ClickhouseConfigInitParameters struct {

	// (Attributes) Access control settings. (see below for nested schema)
	AccessControlImprovements *AccessControlImprovementsInitParameters `json:"accessControlImprovements,omitempty" tf:"access_control_improvements,omitempty"`

	// (Number) Maximum number of threads to parse and insert data in background.
	// Maximum number of threads to parse and insert data in background.
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// (Boolean) Enable or disable asynchronous_insert_log system table.
	// Enable or disable asynchronous_insert_log system table.
	AsynchronousInsertLogEnabled *bool `json:"asynchronousInsertLogEnabled,omitempty" tf:"asynchronous_insert_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	// The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	AsynchronousInsertLogRetentionSize *float64 `json:"asynchronousInsertLogRetentionSize,omitempty" tf:"asynchronous_insert_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_insert_log records will be retained before removal.
	// The maximum time that asynchronous_insert_log records will be retained before removal.
	AsynchronousInsertLogRetentionTime *float64 `json:"asynchronousInsertLogRetentionTime,omitempty" tf:"asynchronous_insert_log_retention_time,omitempty"`

	// (Boolean) Enable or disable asynchronous_metric_log system table.
	// Enable or disable asynchronous_metric_log system table.
	AsynchronousMetricLogEnabled *bool `json:"asynchronousMetricLogEnabled,omitempty" tf:"asynchronous_metric_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	// The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	AsynchronousMetricLogRetentionSize *float64 `json:"asynchronousMetricLogRetentionSize,omitempty" tf:"asynchronous_metric_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_metric_log records will be retained before removal.
	// The maximum time that asynchronous_metric_log records will be retained before removal.
	AsynchronousMetricLogRetentionTime *float64 `json:"asynchronousMetricLogRetentionTime,omitempty" tf:"asynchronous_metric_log_retention_time,omitempty"`

	// engine tables in the background.
	// The maximum number of threads that will be used for performing flush operations for Buffer-engine tables in the background.
	BackgroundBufferFlushSchedulePoolSize *float64 `json:"backgroundBufferFlushSchedulePoolSize,omitempty" tf:"background_buffer_flush_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for performing a variety of operations (mostly garbage collection) for MergeTree-engine tables in a background.
	BackgroundCommonPoolSize *float64 `json:"backgroundCommonPoolSize,omitempty" tf:"background_common_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for executing distributed sends.
	// The maximum number of threads that will be used for executing distributed sends.
	BackgroundDistributedSchedulePoolSize *float64 `json:"backgroundDistributedSchedulePoolSize,omitempty" tf:"background_distributed_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for fetching data parts from another replica for MergeTree-engine tables in a background.
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	// (Number) Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	// Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	// (Number) The maximum number of threads that will be used for executing background operations for message streaming.
	// The maximum number of threads that will be used for executing background operations for message streaming.
	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for moving data parts to another disk or volume for MergeTree-engine tables in a background.
	BackgroundMovePoolSize *float64 `json:"backgroundMovePoolSize,omitempty" tf:"background_move_pool_size,omitempty"`

	// engine tables.
	// Sets the number of threads performing background merges and mutations for MergeTree-engine tables.
	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	// The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// (Number) The maximum number of threads to execute BACKUP requests.
	// The maximum number of threads to execute **BACKUP** requests.
	BackupThreads *float64 `json:"backupThreads,omitempty" tf:"backup_threads,omitempty"`

	// (Attributes List) Data compression configuration. (see below for nested schema)
	Compression []ConfigCompressionInitParameters `json:"compression,omitempty" tf:"compression,omitempty"`

	// (Attributes List) Custom ClickHouse macros. (see below for nested schema)
	CustomMacros []CustomMacrosInitParameters `json:"customMacros,omitempty" tf:"custom_macros,omitempty"`

	// (String) Default database name.
	// Default database name.
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	// (Boolean) Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	// Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	DictionariesLazyLoad *bool `json:"dictionariesLazyLoad,omitempty" tf:"dictionaries_lazy_load,omitempty"`

	// (Boolean) Enables or disables error_log system table.
	// Enables or disables error_log system table.
	ErrorLogEnabled *bool `json:"errorLogEnabled,omitempty" tf:"error_log_enabled,omitempty"`

	// (Number) The maximum size that error_log can grow to before old data will be removed. If set to 0, automatic removal of error_log data based on size is disabled.
	// The maximum size that error_log can grow to before old data will be removed. If set to **0**, automatic removal of error_log data based on size is disabled.
	ErrorLogRetentionSize *float64 `json:"errorLogRetentionSize,omitempty" tf:"error_log_retention_size,omitempty"`

	// (Number) The maximum time that error_log records will be retained before removal. If set to 0, automatic removal of error_log data based on time is disabled.
	// The maximum time that error_log records will be retained before removal. If set to **0**, automatic removal of error_log data based on time is disabled.
	ErrorLogRetentionTime *float64 `json:"errorLogRetentionTime,omitempty" tf:"error_log_retention_time,omitempty"`

	// (Boolean) Enable or disable geobase.
	// Enable or disable geobase.
	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	// (String) Address of the archive with the user geobase in Object Storage.
	// Address of the archive with the user geobase in Object Storage.
	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// (Attributes List) Graphite rollup configuration. (see below for nested schema)
	GraphiteRollup []ConfigGraphiteRollupInitParameters `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// (Attributes) JDBC bridge configuration. (see below for nested schema)
	JdbcBridge *ConfigJdbcBridgeInitParameters `json:"jdbcBridge,omitempty" tf:"jdbc_bridge,omitempty"`

	// (Attributes) Kafka connection configuration. (see below for nested schema)
	Kafka *ConfigKafkaInitParameters `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// (Number) The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	// The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// (String) Logging level.
	// Logging level.
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// (Number) Limit on total number of concurrently executed queries.
	// Limit on total number of concurrently executed queries.
	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	// (Number) Max server connections.
	// Max server connections.
	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	// (Number) Restriction on dropping partitions.
	// Restriction on dropping partitions.
	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	// (Number) Restriction on deleting tables.
	// Restriction on deleting tables.
	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// (Attributes) MergeTree engine configuration. (see below for nested schema)
	MergeTree *ConfigMergeTreeInitParameters `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	// (Boolean) Enable or disable metric_log system table.
	// Enable or disable metric_log system table.
	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	// (Number) The maximum size that metric_log can grow to before old data will be removed.
	// The maximum size that metric_log can grow to before old data will be removed.
	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	// (Number) The maximum time that metric_log records will be retained before removal.
	// The maximum time that metric_log records will be retained before removal.
	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	// (Boolean) Enables or disables MySQL interface on ClickHouse server.
	// Enables or disables MySQL interface on ClickHouse server.
	MySQLProtocol *bool `json:"mysqlProtocol,omitempty" tf:"mysql_protocol,omitempty"`

	// (Boolean) Enable or disable opentelemetry_span_log system table.
	// Enable or disable opentelemetry_span_log system table.
	OpentelemetrySpanLogEnabled *bool `json:"opentelemetrySpanLogEnabled,omitempty" tf:"opentelemetry_span_log_enabled,omitempty"`

	// (Number) The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	// The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	OpentelemetrySpanLogRetentionSize *float64 `json:"opentelemetrySpanLogRetentionSize,omitempty" tf:"opentelemetry_span_log_retention_size,omitempty"`

	// (Number) The maximum time that opentelemetry_span_log records will be retained before removal.
	// The maximum time that opentelemetry_span_log records will be retained before removal.
	OpentelemetrySpanLogRetentionTime *float64 `json:"opentelemetrySpanLogRetentionTime,omitempty" tf:"opentelemetry_span_log_retention_time,omitempty"`

	// (Number) The maximum size that part_log can grow to before old data will be removed.
	// The maximum size that part_log can grow to before old data will be removed.
	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	// (Number) The maximum time that part_log records will be retained before removal.
	// The maximum time that part_log records will be retained before removal.
	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	// (Boolean) Enables or disables processors_profile_log system table.
	// Enables or disables processors_profile_log system table.
	ProcessorsProfileLogEnabled *bool `json:"processorsProfileLogEnabled,omitempty" tf:"processors_profile_log_enabled,omitempty"`

	// (Number) The maximum time that processors_profile_log records will be retained before removal. If set to 0, automatic removal of processors_profile_log data based on time is disabled.
	// The maximum time that processors_profile_log records will be retained before removal. If set to **0**, automatic removal of processors_profile_log data based on time is disabled.
	ProcessorsProfileLogRetentionSize *float64 `json:"processorsProfileLogRetentionSize,omitempty" tf:"processors_profile_log_retention_size,omitempty"`

	// (Number) Enables or disables error_log system table.
	// Enables or disables error_log system table.
	ProcessorsProfileLogRetentionTime *float64 `json:"processorsProfileLogRetentionTime,omitempty" tf:"processors_profile_log_retention_time,omitempty"`

	// (Attributes) Query cache configuration. (see below for nested schema)
	QueryCache *ConfigQueryCacheInitParameters `json:"queryCache,omitempty" tf:"query_cache,omitempty"`

	// (Number) The maximum size that query_log can grow to before old data will be removed.
	// The maximum size that query_log can grow to before old data will be removed.
	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	// (Number) The maximum time that query_log records will be retained before removal.
	// The maximum time that query_log records will be retained before removal.
	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	// (Attributes List) Query masking rules configuration. (see below for nested schema)
	QueryMaskingRules []ConfigQueryMaskingRulesInitParameters `json:"queryMaskingRules,omitempty" tf:"query_masking_rules,omitempty"`

	// (Boolean) Enable or disable query_thread_log system table.
	// Enable or disable query_thread_log system table.
	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	// (Number) The maximum size that query_thread_log can grow to before old data will be removed.
	// The maximum size that query_thread_log can grow to before old data will be removed.
	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	// (Number) The maximum time that query_thread_log records will be retained before removal.
	// The maximum time that query_thread_log records will be retained before removal.
	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// (Boolean) Enable or disable query_views_log system table.
	// Enable or disable query_views_log system table.
	QueryViewsLogEnabled *bool `json:"queryViewsLogEnabled,omitempty" tf:"query_views_log_enabled,omitempty"`

	// (Number) The maximum size that query_views_log can grow to before old data will be removed.
	// The maximum size that query_views_log can grow to before old data will be removed.
	QueryViewsLogRetentionSize *float64 `json:"queryViewsLogRetentionSize,omitempty" tf:"query_views_log_retention_size,omitempty"`

	// (Number) The maximum time that query_views_log records will be retained before removal.
	// The maximum time that query_views_log records will be retained before removal.
	QueryViewsLogRetentionTime *float64 `json:"queryViewsLogRetentionTime,omitempty" tf:"query_views_log_retention_time,omitempty"`

	// (Attributes) RabbitMQ connection configuration. (see below for nested schema)
	Rabbitmq *ConfigRabbitmqInitParameters `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	// (Number) The maximum number of threads to execute RESTORE requests.
	// The maximum number of threads to execute **RESTORE** requests.
	RestoreThreads *float64 `json:"restoreThreads,omitempty" tf:"restore_threads,omitempty"`

	// (Boolean) Enable or disable session_log system table.
	// Enable or disable session_log system table.
	SessionLogEnabled *bool `json:"sessionLogEnabled,omitempty" tf:"session_log_enabled,omitempty"`

	// (Number) The maximum size that session_log can grow to before old data will be removed.
	// The maximum size that session_log can grow to before old data will be removed.
	SessionLogRetentionSize *float64 `json:"sessionLogRetentionSize,omitempty" tf:"session_log_retention_size,omitempty"`

	// (Number) The maximum time that session_log records will be retained before removal.
	// The maximum time that session_log records will be retained before removal.
	SessionLogRetentionTime *float64 `json:"sessionLogRetentionTime,omitempty" tf:"session_log_retention_time,omitempty"`

	// (Boolean) Enable or disable text_log system table.
	// Enable or disable text_log system table.
	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	// (String) Logging level for text_log system table.
	// Logging level for text_log system table.
	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	// (Number) The maximum size that text_log can grow to before old data will be removed.
	// The maximum size that text_log can grow to before old data will be removed.
	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	// (Number) The maximum time that text_log records will be retained before removal.
	// The maximum time that text_log records will be retained before removal.
	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	// (String) The server's time zone.
	// The server's time zone.
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (Number) Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	// Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	// allocations and writes them in the system.trace_log system table with trace_type equal to a MemorySample with the specified probability.
	// Allows to collect random allocations and de-allocations and writes them in the system.trace_log system table with trace_type equal to a MemorySample with the specified probability.
	TotalMemoryTrackerSampleProbability *float64 `json:"totalMemoryTrackerSampleProbability,omitempty" tf:"total_memory_tracker_sample_probability,omitempty"`

	// (Boolean) Enable or disable trace_log system table.
	// Enable or disable trace_log system table.
	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	// (Number) The maximum size that trace_log can grow to before old data will be removed.
	// The maximum size that trace_log can grow to before old data will be removed.
	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	// (Number) The maximum time that trace_log records will be retained before removal.
	// The maximum time that trace_log records will be retained before removal.
	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	// (Number) Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	// Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`

	// (Boolean) Enable or disable zookeeper_log system table.
	// Enable or disable zookeeper_log system table.
	ZookeeperLogEnabled *bool `json:"zookeeperLogEnabled,omitempty" tf:"zookeeper_log_enabled,omitempty"`

	// (Number) The maximum size that zookeeper_log can grow to before old data will be removed.
	// The maximum size that zookeeper_log can grow to before old data will be removed.
	ZookeeperLogRetentionSize *float64 `json:"zookeeperLogRetentionSize,omitempty" tf:"zookeeper_log_retention_size,omitempty"`

	// (Number) The maximum time that zookeeper_log records will be retained before removal.
	// The maximum time that zookeeper_log records will be retained before removal.
	ZookeeperLogRetentionTime *float64 `json:"zookeeperLogRetentionTime,omitempty" tf:"zookeeper_log_retention_time,omitempty"`
}

type ClickhouseConfigObservation struct {

	// (Attributes) Access control settings. (see below for nested schema)
	AccessControlImprovements *AccessControlImprovementsObservation `json:"accessControlImprovements,omitempty" tf:"access_control_improvements,omitempty"`

	// (Number) Maximum number of threads to parse and insert data in background.
	// Maximum number of threads to parse and insert data in background.
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// (Boolean) Enable or disable asynchronous_insert_log system table.
	// Enable or disable asynchronous_insert_log system table.
	AsynchronousInsertLogEnabled *bool `json:"asynchronousInsertLogEnabled,omitempty" tf:"asynchronous_insert_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	// The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	AsynchronousInsertLogRetentionSize *float64 `json:"asynchronousInsertLogRetentionSize,omitempty" tf:"asynchronous_insert_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_insert_log records will be retained before removal.
	// The maximum time that asynchronous_insert_log records will be retained before removal.
	AsynchronousInsertLogRetentionTime *float64 `json:"asynchronousInsertLogRetentionTime,omitempty" tf:"asynchronous_insert_log_retention_time,omitempty"`

	// (Boolean) Enable or disable asynchronous_metric_log system table.
	// Enable or disable asynchronous_metric_log system table.
	AsynchronousMetricLogEnabled *bool `json:"asynchronousMetricLogEnabled,omitempty" tf:"asynchronous_metric_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	// The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	AsynchronousMetricLogRetentionSize *float64 `json:"asynchronousMetricLogRetentionSize,omitempty" tf:"asynchronous_metric_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_metric_log records will be retained before removal.
	// The maximum time that asynchronous_metric_log records will be retained before removal.
	AsynchronousMetricLogRetentionTime *float64 `json:"asynchronousMetricLogRetentionTime,omitempty" tf:"asynchronous_metric_log_retention_time,omitempty"`

	// engine tables in the background.
	// The maximum number of threads that will be used for performing flush operations for Buffer-engine tables in the background.
	BackgroundBufferFlushSchedulePoolSize *float64 `json:"backgroundBufferFlushSchedulePoolSize,omitempty" tf:"background_buffer_flush_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for performing a variety of operations (mostly garbage collection) for MergeTree-engine tables in a background.
	BackgroundCommonPoolSize *float64 `json:"backgroundCommonPoolSize,omitempty" tf:"background_common_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for executing distributed sends.
	// The maximum number of threads that will be used for executing distributed sends.
	BackgroundDistributedSchedulePoolSize *float64 `json:"backgroundDistributedSchedulePoolSize,omitempty" tf:"background_distributed_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for fetching data parts from another replica for MergeTree-engine tables in a background.
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	// (Number) Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	// Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	// (Number) The maximum number of threads that will be used for executing background operations for message streaming.
	// The maximum number of threads that will be used for executing background operations for message streaming.
	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for moving data parts to another disk or volume for MergeTree-engine tables in a background.
	BackgroundMovePoolSize *float64 `json:"backgroundMovePoolSize,omitempty" tf:"background_move_pool_size,omitempty"`

	// engine tables.
	// Sets the number of threads performing background merges and mutations for MergeTree-engine tables.
	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	// The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// (Number) The maximum number of threads to execute BACKUP requests.
	// The maximum number of threads to execute **BACKUP** requests.
	BackupThreads *float64 `json:"backupThreads,omitempty" tf:"backup_threads,omitempty"`

	// (Attributes List) Data compression configuration. (see below for nested schema)
	Compression []ConfigCompressionObservation `json:"compression,omitempty" tf:"compression,omitempty"`

	// (Attributes List) Custom ClickHouse macros. (see below for nested schema)
	CustomMacros []CustomMacrosObservation `json:"customMacros,omitempty" tf:"custom_macros,omitempty"`

	// (String) Default database name.
	// Default database name.
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	// (Boolean) Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	// Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	DictionariesLazyLoad *bool `json:"dictionariesLazyLoad,omitempty" tf:"dictionaries_lazy_load,omitempty"`

	// (Boolean) Enables or disables error_log system table.
	// Enables or disables error_log system table.
	ErrorLogEnabled *bool `json:"errorLogEnabled,omitempty" tf:"error_log_enabled,omitempty"`

	// (Number) The maximum size that error_log can grow to before old data will be removed. If set to 0, automatic removal of error_log data based on size is disabled.
	// The maximum size that error_log can grow to before old data will be removed. If set to **0**, automatic removal of error_log data based on size is disabled.
	ErrorLogRetentionSize *float64 `json:"errorLogRetentionSize,omitempty" tf:"error_log_retention_size,omitempty"`

	// (Number) The maximum time that error_log records will be retained before removal. If set to 0, automatic removal of error_log data based on time is disabled.
	// The maximum time that error_log records will be retained before removal. If set to **0**, automatic removal of error_log data based on time is disabled.
	ErrorLogRetentionTime *float64 `json:"errorLogRetentionTime,omitempty" tf:"error_log_retention_time,omitempty"`

	// (Boolean) Enable or disable geobase.
	// Enable or disable geobase.
	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	// (String) Address of the archive with the user geobase in Object Storage.
	// Address of the archive with the user geobase in Object Storage.
	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// (Attributes List) Graphite rollup configuration. (see below for nested schema)
	GraphiteRollup []ConfigGraphiteRollupObservation `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// (Attributes) JDBC bridge configuration. (see below for nested schema)
	JdbcBridge *ConfigJdbcBridgeObservation `json:"jdbcBridge,omitempty" tf:"jdbc_bridge,omitempty"`

	// (Attributes) Kafka connection configuration. (see below for nested schema)
	Kafka *ConfigKafkaObservation `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// (Number) The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	// The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// (String) Logging level.
	// Logging level.
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// (Number) Limit on total number of concurrently executed queries.
	// Limit on total number of concurrently executed queries.
	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	// (Number) Max server connections.
	// Max server connections.
	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	// (Number) Restriction on dropping partitions.
	// Restriction on dropping partitions.
	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	// (Number) Restriction on deleting tables.
	// Restriction on deleting tables.
	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// (Attributes) MergeTree engine configuration. (see below for nested schema)
	MergeTree *ConfigMergeTreeObservation `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	// (Boolean) Enable or disable metric_log system table.
	// Enable or disable metric_log system table.
	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	// (Number) The maximum size that metric_log can grow to before old data will be removed.
	// The maximum size that metric_log can grow to before old data will be removed.
	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	// (Number) The maximum time that metric_log records will be retained before removal.
	// The maximum time that metric_log records will be retained before removal.
	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	// (Boolean) Enables or disables MySQL interface on ClickHouse server.
	// Enables or disables MySQL interface on ClickHouse server.
	MySQLProtocol *bool `json:"mysqlProtocol,omitempty" tf:"mysql_protocol,omitempty"`

	// (Boolean) Enable or disable opentelemetry_span_log system table.
	// Enable or disable opentelemetry_span_log system table.
	OpentelemetrySpanLogEnabled *bool `json:"opentelemetrySpanLogEnabled,omitempty" tf:"opentelemetry_span_log_enabled,omitempty"`

	// (Number) The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	// The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	OpentelemetrySpanLogRetentionSize *float64 `json:"opentelemetrySpanLogRetentionSize,omitempty" tf:"opentelemetry_span_log_retention_size,omitempty"`

	// (Number) The maximum time that opentelemetry_span_log records will be retained before removal.
	// The maximum time that opentelemetry_span_log records will be retained before removal.
	OpentelemetrySpanLogRetentionTime *float64 `json:"opentelemetrySpanLogRetentionTime,omitempty" tf:"opentelemetry_span_log_retention_time,omitempty"`

	// (Number) The maximum size that part_log can grow to before old data will be removed.
	// The maximum size that part_log can grow to before old data will be removed.
	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	// (Number) The maximum time that part_log records will be retained before removal.
	// The maximum time that part_log records will be retained before removal.
	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	// (Boolean) Enables or disables processors_profile_log system table.
	// Enables or disables processors_profile_log system table.
	ProcessorsProfileLogEnabled *bool `json:"processorsProfileLogEnabled,omitempty" tf:"processors_profile_log_enabled,omitempty"`

	// (Number) The maximum time that processors_profile_log records will be retained before removal. If set to 0, automatic removal of processors_profile_log data based on time is disabled.
	// The maximum time that processors_profile_log records will be retained before removal. If set to **0**, automatic removal of processors_profile_log data based on time is disabled.
	ProcessorsProfileLogRetentionSize *float64 `json:"processorsProfileLogRetentionSize,omitempty" tf:"processors_profile_log_retention_size,omitempty"`

	// (Number) Enables or disables error_log system table.
	// Enables or disables error_log system table.
	ProcessorsProfileLogRetentionTime *float64 `json:"processorsProfileLogRetentionTime,omitempty" tf:"processors_profile_log_retention_time,omitempty"`

	// (Attributes) Query cache configuration. (see below for nested schema)
	QueryCache *ConfigQueryCacheObservation `json:"queryCache,omitempty" tf:"query_cache,omitempty"`

	// (Number) The maximum size that query_log can grow to before old data will be removed.
	// The maximum size that query_log can grow to before old data will be removed.
	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	// (Number) The maximum time that query_log records will be retained before removal.
	// The maximum time that query_log records will be retained before removal.
	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	// (Attributes List) Query masking rules configuration. (see below for nested schema)
	QueryMaskingRules []ConfigQueryMaskingRulesObservation `json:"queryMaskingRules,omitempty" tf:"query_masking_rules,omitempty"`

	// (Boolean) Enable or disable query_thread_log system table.
	// Enable or disable query_thread_log system table.
	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	// (Number) The maximum size that query_thread_log can grow to before old data will be removed.
	// The maximum size that query_thread_log can grow to before old data will be removed.
	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	// (Number) The maximum time that query_thread_log records will be retained before removal.
	// The maximum time that query_thread_log records will be retained before removal.
	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// (Boolean) Enable or disable query_views_log system table.
	// Enable or disable query_views_log system table.
	QueryViewsLogEnabled *bool `json:"queryViewsLogEnabled,omitempty" tf:"query_views_log_enabled,omitempty"`

	// (Number) The maximum size that query_views_log can grow to before old data will be removed.
	// The maximum size that query_views_log can grow to before old data will be removed.
	QueryViewsLogRetentionSize *float64 `json:"queryViewsLogRetentionSize,omitempty" tf:"query_views_log_retention_size,omitempty"`

	// (Number) The maximum time that query_views_log records will be retained before removal.
	// The maximum time that query_views_log records will be retained before removal.
	QueryViewsLogRetentionTime *float64 `json:"queryViewsLogRetentionTime,omitempty" tf:"query_views_log_retention_time,omitempty"`

	// (Attributes) RabbitMQ connection configuration. (see below for nested schema)
	Rabbitmq *ConfigRabbitmqObservation `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	// (Number) The maximum number of threads to execute RESTORE requests.
	// The maximum number of threads to execute **RESTORE** requests.
	RestoreThreads *float64 `json:"restoreThreads,omitempty" tf:"restore_threads,omitempty"`

	// (Boolean) Enable or disable session_log system table.
	// Enable or disable session_log system table.
	SessionLogEnabled *bool `json:"sessionLogEnabled,omitempty" tf:"session_log_enabled,omitempty"`

	// (Number) The maximum size that session_log can grow to before old data will be removed.
	// The maximum size that session_log can grow to before old data will be removed.
	SessionLogRetentionSize *float64 `json:"sessionLogRetentionSize,omitempty" tf:"session_log_retention_size,omitempty"`

	// (Number) The maximum time that session_log records will be retained before removal.
	// The maximum time that session_log records will be retained before removal.
	SessionLogRetentionTime *float64 `json:"sessionLogRetentionTime,omitempty" tf:"session_log_retention_time,omitempty"`

	// (Boolean) Enable or disable text_log system table.
	// Enable or disable text_log system table.
	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	// (String) Logging level for text_log system table.
	// Logging level for text_log system table.
	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	// (Number) The maximum size that text_log can grow to before old data will be removed.
	// The maximum size that text_log can grow to before old data will be removed.
	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	// (Number) The maximum time that text_log records will be retained before removal.
	// The maximum time that text_log records will be retained before removal.
	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	// (String) The server's time zone.
	// The server's time zone.
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (Number) Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	// Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	// allocations and writes them in the system.trace_log system table with trace_type equal to a MemorySample with the specified probability.
	// Allows to collect random allocations and de-allocations and writes them in the system.trace_log system table with trace_type equal to a MemorySample with the specified probability.
	TotalMemoryTrackerSampleProbability *float64 `json:"totalMemoryTrackerSampleProbability,omitempty" tf:"total_memory_tracker_sample_probability,omitempty"`

	// (Boolean) Enable or disable trace_log system table.
	// Enable or disable trace_log system table.
	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	// (Number) The maximum size that trace_log can grow to before old data will be removed.
	// The maximum size that trace_log can grow to before old data will be removed.
	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	// (Number) The maximum time that trace_log records will be retained before removal.
	// The maximum time that trace_log records will be retained before removal.
	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	// (Number) Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	// Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`

	// (Boolean) Enable or disable zookeeper_log system table.
	// Enable or disable zookeeper_log system table.
	ZookeeperLogEnabled *bool `json:"zookeeperLogEnabled,omitempty" tf:"zookeeper_log_enabled,omitempty"`

	// (Number) The maximum size that zookeeper_log can grow to before old data will be removed.
	// The maximum size that zookeeper_log can grow to before old data will be removed.
	ZookeeperLogRetentionSize *float64 `json:"zookeeperLogRetentionSize,omitempty" tf:"zookeeper_log_retention_size,omitempty"`

	// (Number) The maximum time that zookeeper_log records will be retained before removal.
	// The maximum time that zookeeper_log records will be retained before removal.
	ZookeeperLogRetentionTime *float64 `json:"zookeeperLogRetentionTime,omitempty" tf:"zookeeper_log_retention_time,omitempty"`
}

type ClickhouseConfigParameters struct {

	// (Attributes) Access control settings. (see below for nested schema)
	// +kubebuilder:validation:Optional
	AccessControlImprovements *AccessControlImprovementsParameters `json:"accessControlImprovements,omitempty" tf:"access_control_improvements,omitempty"`

	// (Number) Maximum number of threads to parse and insert data in background.
	// Maximum number of threads to parse and insert data in background.
	// +kubebuilder:validation:Optional
	AsyncInsertThreads *float64 `json:"asyncInsertThreads,omitempty" tf:"async_insert_threads,omitempty"`

	// (Boolean) Enable or disable asynchronous_insert_log system table.
	// Enable or disable asynchronous_insert_log system table.
	// +kubebuilder:validation:Optional
	AsynchronousInsertLogEnabled *bool `json:"asynchronousInsertLogEnabled,omitempty" tf:"asynchronous_insert_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	// The maximum size that asynchronous_insert_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	AsynchronousInsertLogRetentionSize *float64 `json:"asynchronousInsertLogRetentionSize,omitempty" tf:"asynchronous_insert_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_insert_log records will be retained before removal.
	// The maximum time that asynchronous_insert_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	AsynchronousInsertLogRetentionTime *float64 `json:"asynchronousInsertLogRetentionTime,omitempty" tf:"asynchronous_insert_log_retention_time,omitempty"`

	// (Boolean) Enable or disable asynchronous_metric_log system table.
	// Enable or disable asynchronous_metric_log system table.
	// +kubebuilder:validation:Optional
	AsynchronousMetricLogEnabled *bool `json:"asynchronousMetricLogEnabled,omitempty" tf:"asynchronous_metric_log_enabled,omitempty"`

	// (Number) The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	// The maximum size that asynchronous_metric_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	AsynchronousMetricLogRetentionSize *float64 `json:"asynchronousMetricLogRetentionSize,omitempty" tf:"asynchronous_metric_log_retention_size,omitempty"`

	// (Number) The maximum time that asynchronous_metric_log records will be retained before removal.
	// The maximum time that asynchronous_metric_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	AsynchronousMetricLogRetentionTime *float64 `json:"asynchronousMetricLogRetentionTime,omitempty" tf:"asynchronous_metric_log_retention_time,omitempty"`

	// engine tables in the background.
	// The maximum number of threads that will be used for performing flush operations for Buffer-engine tables in the background.
	// +kubebuilder:validation:Optional
	BackgroundBufferFlushSchedulePoolSize *float64 `json:"backgroundBufferFlushSchedulePoolSize,omitempty" tf:"background_buffer_flush_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for performing a variety of operations (mostly garbage collection) for MergeTree-engine tables in a background.
	// +kubebuilder:validation:Optional
	BackgroundCommonPoolSize *float64 `json:"backgroundCommonPoolSize,omitempty" tf:"background_common_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for executing distributed sends.
	// The maximum number of threads that will be used for executing distributed sends.
	// +kubebuilder:validation:Optional
	BackgroundDistributedSchedulePoolSize *float64 `json:"backgroundDistributedSchedulePoolSize,omitempty" tf:"background_distributed_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for fetching data parts from another replica for MergeTree-engine tables in a background.
	// +kubebuilder:validation:Optional
	BackgroundFetchesPoolSize *float64 `json:"backgroundFetchesPoolSize,omitempty" tf:"background_fetches_pool_size,omitempty"`

	// (Number) Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	// Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
	// +kubebuilder:validation:Optional
	BackgroundMergesMutationsConcurrencyRatio *float64 `json:"backgroundMergesMutationsConcurrencyRatio,omitempty" tf:"background_merges_mutations_concurrency_ratio,omitempty"`

	// (Number) The maximum number of threads that will be used for executing background operations for message streaming.
	// The maximum number of threads that will be used for executing background operations for message streaming.
	// +kubebuilder:validation:Optional
	BackgroundMessageBrokerSchedulePoolSize *float64 `json:"backgroundMessageBrokerSchedulePoolSize,omitempty" tf:"background_message_broker_schedule_pool_size,omitempty"`

	// engine tables in a background.
	// The maximum number of threads that will be used for moving data parts to another disk or volume for MergeTree-engine tables in a background.
	// +kubebuilder:validation:Optional
	BackgroundMovePoolSize *float64 `json:"backgroundMovePoolSize,omitempty" tf:"background_move_pool_size,omitempty"`

	// engine tables.
	// Sets the number of threads performing background merges and mutations for MergeTree-engine tables.
	// +kubebuilder:validation:Optional
	BackgroundPoolSize *float64 `json:"backgroundPoolSize,omitempty" tf:"background_pool_size,omitempty"`

	// (Number) The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	// The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
	// +kubebuilder:validation:Optional
	BackgroundSchedulePoolSize *float64 `json:"backgroundSchedulePoolSize,omitempty" tf:"background_schedule_pool_size,omitempty"`

	// (Number) The maximum number of threads to execute BACKUP requests.
	// The maximum number of threads to execute **BACKUP** requests.
	// +kubebuilder:validation:Optional
	BackupThreads *float64 `json:"backupThreads,omitempty" tf:"backup_threads,omitempty"`

	// (Attributes List) Data compression configuration. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Compression []ConfigCompressionParameters `json:"compression,omitempty" tf:"compression,omitempty"`

	// (Attributes List) Custom ClickHouse macros. (see below for nested schema)
	// +kubebuilder:validation:Optional
	CustomMacros []CustomMacrosParameters `json:"customMacros,omitempty" tf:"custom_macros,omitempty"`

	// (String) Default database name.
	// Default database name.
	// +kubebuilder:validation:Optional
	DefaultDatabase *string `json:"defaultDatabase,omitempty" tf:"default_database,omitempty"`

	// (Boolean) Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	// Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
	// +kubebuilder:validation:Optional
	DictionariesLazyLoad *bool `json:"dictionariesLazyLoad,omitempty" tf:"dictionaries_lazy_load,omitempty"`

	// (Boolean) Enables or disables error_log system table.
	// Enables or disables error_log system table.
	// +kubebuilder:validation:Optional
	ErrorLogEnabled *bool `json:"errorLogEnabled,omitempty" tf:"error_log_enabled,omitempty"`

	// (Number) The maximum size that error_log can grow to before old data will be removed. If set to 0, automatic removal of error_log data based on size is disabled.
	// The maximum size that error_log can grow to before old data will be removed. If set to **0**, automatic removal of error_log data based on size is disabled.
	// +kubebuilder:validation:Optional
	ErrorLogRetentionSize *float64 `json:"errorLogRetentionSize,omitempty" tf:"error_log_retention_size,omitempty"`

	// (Number) The maximum time that error_log records will be retained before removal. If set to 0, automatic removal of error_log data based on time is disabled.
	// The maximum time that error_log records will be retained before removal. If set to **0**, automatic removal of error_log data based on time is disabled.
	// +kubebuilder:validation:Optional
	ErrorLogRetentionTime *float64 `json:"errorLogRetentionTime,omitempty" tf:"error_log_retention_time,omitempty"`

	// (Boolean) Enable or disable geobase.
	// Enable or disable geobase.
	// +kubebuilder:validation:Optional
	GeobaseEnabled *bool `json:"geobaseEnabled,omitempty" tf:"geobase_enabled,omitempty"`

	// (String) Address of the archive with the user geobase in Object Storage.
	// Address of the archive with the user geobase in Object Storage.
	// +kubebuilder:validation:Optional
	GeobaseURI *string `json:"geobaseUri,omitempty" tf:"geobase_uri,omitempty"`

	// (Attributes List) Graphite rollup configuration. (see below for nested schema)
	// +kubebuilder:validation:Optional
	GraphiteRollup []ConfigGraphiteRollupParameters `json:"graphiteRollup,omitempty" tf:"graphite_rollup,omitempty"`

	// (Attributes) JDBC bridge configuration. (see below for nested schema)
	// +kubebuilder:validation:Optional
	JdbcBridge *ConfigJdbcBridgeParameters `json:"jdbcBridge,omitempty" tf:"jdbc_bridge,omitempty"`

	// (Attributes) Kafka connection configuration. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Kafka *ConfigKafkaParameters `json:"kafka,omitempty" tf:"kafka,omitempty"`

	// (Number) The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	// The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
	// +kubebuilder:validation:Optional
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitempty" tf:"keep_alive_timeout,omitempty"`

	// (String) Logging level.
	// Logging level.
	// +kubebuilder:validation:Optional
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// (Number) Limit on total number of concurrently executed queries.
	// Limit on total number of concurrently executed queries.
	// +kubebuilder:validation:Optional
	MaxConcurrentQueries *float64 `json:"maxConcurrentQueries,omitempty" tf:"max_concurrent_queries,omitempty"`

	// (Number) Max server connections.
	// Max server connections.
	// +kubebuilder:validation:Optional
	MaxConnections *float64 `json:"maxConnections,omitempty" tf:"max_connections,omitempty"`

	// (Number) Restriction on dropping partitions.
	// Restriction on dropping partitions.
	// +kubebuilder:validation:Optional
	MaxPartitionSizeToDrop *float64 `json:"maxPartitionSizeToDrop,omitempty" tf:"max_partition_size_to_drop,omitempty"`

	// (Number) Restriction on deleting tables.
	// Restriction on deleting tables.
	// +kubebuilder:validation:Optional
	MaxTableSizeToDrop *float64 `json:"maxTableSizeToDrop,omitempty" tf:"max_table_size_to_drop,omitempty"`

	// (Attributes) MergeTree engine configuration. (see below for nested schema)
	// +kubebuilder:validation:Optional
	MergeTree *ConfigMergeTreeParameters `json:"mergeTree,omitempty" tf:"merge_tree,omitempty"`

	// (Boolean) Enable or disable metric_log system table.
	// Enable or disable metric_log system table.
	// +kubebuilder:validation:Optional
	MetricLogEnabled *bool `json:"metricLogEnabled,omitempty" tf:"metric_log_enabled,omitempty"`

	// (Number) The maximum size that metric_log can grow to before old data will be removed.
	// The maximum size that metric_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	MetricLogRetentionSize *float64 `json:"metricLogRetentionSize,omitempty" tf:"metric_log_retention_size,omitempty"`

	// (Number) The maximum time that metric_log records will be retained before removal.
	// The maximum time that metric_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	MetricLogRetentionTime *float64 `json:"metricLogRetentionTime,omitempty" tf:"metric_log_retention_time,omitempty"`

	// (Boolean) Enables or disables MySQL interface on ClickHouse server.
	// Enables or disables MySQL interface on ClickHouse server.
	// +kubebuilder:validation:Optional
	MySQLProtocol *bool `json:"mysqlProtocol,omitempty" tf:"mysql_protocol,omitempty"`

	// (Boolean) Enable or disable opentelemetry_span_log system table.
	// Enable or disable opentelemetry_span_log system table.
	// +kubebuilder:validation:Optional
	OpentelemetrySpanLogEnabled *bool `json:"opentelemetrySpanLogEnabled,omitempty" tf:"opentelemetry_span_log_enabled,omitempty"`

	// (Number) The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	// The maximum size that opentelemetry_span_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	OpentelemetrySpanLogRetentionSize *float64 `json:"opentelemetrySpanLogRetentionSize,omitempty" tf:"opentelemetry_span_log_retention_size,omitempty"`

	// (Number) The maximum time that opentelemetry_span_log records will be retained before removal.
	// The maximum time that opentelemetry_span_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	OpentelemetrySpanLogRetentionTime *float64 `json:"opentelemetrySpanLogRetentionTime,omitempty" tf:"opentelemetry_span_log_retention_time,omitempty"`

	// (Number) The maximum size that part_log can grow to before old data will be removed.
	// The maximum size that part_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	PartLogRetentionSize *float64 `json:"partLogRetentionSize,omitempty" tf:"part_log_retention_size,omitempty"`

	// (Number) The maximum time that part_log records will be retained before removal.
	// The maximum time that part_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	PartLogRetentionTime *float64 `json:"partLogRetentionTime,omitempty" tf:"part_log_retention_time,omitempty"`

	// (Boolean) Enables or disables processors_profile_log system table.
	// Enables or disables processors_profile_log system table.
	// +kubebuilder:validation:Optional
	ProcessorsProfileLogEnabled *bool `json:"processorsProfileLogEnabled,omitempty" tf:"processors_profile_log_enabled,omitempty"`

	// (Number) The maximum time that processors_profile_log records will be retained before removal. If set to 0, automatic removal of processors_profile_log data based on time is disabled.
	// The maximum time that processors_profile_log records will be retained before removal. If set to **0**, automatic removal of processors_profile_log data based on time is disabled.
	// +kubebuilder:validation:Optional
	ProcessorsProfileLogRetentionSize *float64 `json:"processorsProfileLogRetentionSize,omitempty" tf:"processors_profile_log_retention_size,omitempty"`

	// (Number) Enables or disables error_log system table.
	// Enables or disables error_log system table.
	// +kubebuilder:validation:Optional
	ProcessorsProfileLogRetentionTime *float64 `json:"processorsProfileLogRetentionTime,omitempty" tf:"processors_profile_log_retention_time,omitempty"`

	// (Attributes) Query cache configuration. (see below for nested schema)
	// +kubebuilder:validation:Optional
	QueryCache *ConfigQueryCacheParameters `json:"queryCache,omitempty" tf:"query_cache,omitempty"`

	// (Number) The maximum size that query_log can grow to before old data will be removed.
	// The maximum size that query_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	QueryLogRetentionSize *float64 `json:"queryLogRetentionSize,omitempty" tf:"query_log_retention_size,omitempty"`

	// (Number) The maximum time that query_log records will be retained before removal.
	// The maximum time that query_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	QueryLogRetentionTime *float64 `json:"queryLogRetentionTime,omitempty" tf:"query_log_retention_time,omitempty"`

	// (Attributes List) Query masking rules configuration. (see below for nested schema)
	// +kubebuilder:validation:Optional
	QueryMaskingRules []ConfigQueryMaskingRulesParameters `json:"queryMaskingRules,omitempty" tf:"query_masking_rules,omitempty"`

	// (Boolean) Enable or disable query_thread_log system table.
	// Enable or disable query_thread_log system table.
	// +kubebuilder:validation:Optional
	QueryThreadLogEnabled *bool `json:"queryThreadLogEnabled,omitempty" tf:"query_thread_log_enabled,omitempty"`

	// (Number) The maximum size that query_thread_log can grow to before old data will be removed.
	// The maximum size that query_thread_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	QueryThreadLogRetentionSize *float64 `json:"queryThreadLogRetentionSize,omitempty" tf:"query_thread_log_retention_size,omitempty"`

	// (Number) The maximum time that query_thread_log records will be retained before removal.
	// The maximum time that query_thread_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	QueryThreadLogRetentionTime *float64 `json:"queryThreadLogRetentionTime,omitempty" tf:"query_thread_log_retention_time,omitempty"`

	// (Boolean) Enable or disable query_views_log system table.
	// Enable or disable query_views_log system table.
	// +kubebuilder:validation:Optional
	QueryViewsLogEnabled *bool `json:"queryViewsLogEnabled,omitempty" tf:"query_views_log_enabled,omitempty"`

	// (Number) The maximum size that query_views_log can grow to before old data will be removed.
	// The maximum size that query_views_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	QueryViewsLogRetentionSize *float64 `json:"queryViewsLogRetentionSize,omitempty" tf:"query_views_log_retention_size,omitempty"`

	// (Number) The maximum time that query_views_log records will be retained before removal.
	// The maximum time that query_views_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	QueryViewsLogRetentionTime *float64 `json:"queryViewsLogRetentionTime,omitempty" tf:"query_views_log_retention_time,omitempty"`

	// (Attributes) RabbitMQ connection configuration. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Rabbitmq *ConfigRabbitmqParameters `json:"rabbitmq,omitempty" tf:"rabbitmq,omitempty"`

	// (Number) The maximum number of threads to execute RESTORE requests.
	// The maximum number of threads to execute **RESTORE** requests.
	// +kubebuilder:validation:Optional
	RestoreThreads *float64 `json:"restoreThreads,omitempty" tf:"restore_threads,omitempty"`

	// (Boolean) Enable or disable session_log system table.
	// Enable or disable session_log system table.
	// +kubebuilder:validation:Optional
	SessionLogEnabled *bool `json:"sessionLogEnabled,omitempty" tf:"session_log_enabled,omitempty"`

	// (Number) The maximum size that session_log can grow to before old data will be removed.
	// The maximum size that session_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	SessionLogRetentionSize *float64 `json:"sessionLogRetentionSize,omitempty" tf:"session_log_retention_size,omitempty"`

	// (Number) The maximum time that session_log records will be retained before removal.
	// The maximum time that session_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	SessionLogRetentionTime *float64 `json:"sessionLogRetentionTime,omitempty" tf:"session_log_retention_time,omitempty"`

	// (Boolean) Enable or disable text_log system table.
	// Enable or disable text_log system table.
	// +kubebuilder:validation:Optional
	TextLogEnabled *bool `json:"textLogEnabled,omitempty" tf:"text_log_enabled,omitempty"`

	// (String) Logging level for text_log system table.
	// Logging level for text_log system table.
	// +kubebuilder:validation:Optional
	TextLogLevel *string `json:"textLogLevel,omitempty" tf:"text_log_level,omitempty"`

	// (Number) The maximum size that text_log can grow to before old data will be removed.
	// The maximum size that text_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	TextLogRetentionSize *float64 `json:"textLogRetentionSize,omitempty" tf:"text_log_retention_size,omitempty"`

	// (Number) The maximum time that text_log records will be retained before removal.
	// The maximum time that text_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	TextLogRetentionTime *float64 `json:"textLogRetentionTime,omitempty" tf:"text_log_retention_time,omitempty"`

	// (String) The server's time zone.
	// The server's time zone.
	// +kubebuilder:validation:Optional
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (Number) Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	// Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
	// +kubebuilder:validation:Optional
	TotalMemoryProfilerStep *float64 `json:"totalMemoryProfilerStep,omitempty" tf:"total_memory_profiler_step,omitempty"`

	// allocations and writes them in the system.trace_log system table with trace_type equal to a MemorySample with the specified probability.
	// Allows to collect random allocations and de-allocations and writes them in the system.trace_log system table with trace_type equal to a MemorySample with the specified probability.
	// +kubebuilder:validation:Optional
	TotalMemoryTrackerSampleProbability *float64 `json:"totalMemoryTrackerSampleProbability,omitempty" tf:"total_memory_tracker_sample_probability,omitempty"`

	// (Boolean) Enable or disable trace_log system table.
	// Enable or disable trace_log system table.
	// +kubebuilder:validation:Optional
	TraceLogEnabled *bool `json:"traceLogEnabled,omitempty" tf:"trace_log_enabled,omitempty"`

	// (Number) The maximum size that trace_log can grow to before old data will be removed.
	// The maximum size that trace_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	TraceLogRetentionSize *float64 `json:"traceLogRetentionSize,omitempty" tf:"trace_log_retention_size,omitempty"`

	// (Number) The maximum time that trace_log records will be retained before removal.
	// The maximum time that trace_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	TraceLogRetentionTime *float64 `json:"traceLogRetentionTime,omitempty" tf:"trace_log_retention_time,omitempty"`

	// (Number) Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	// Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
	// +kubebuilder:validation:Optional
	UncompressedCacheSize *float64 `json:"uncompressedCacheSize,omitempty" tf:"uncompressed_cache_size,omitempty"`

	// (Boolean) Enable or disable zookeeper_log system table.
	// Enable or disable zookeeper_log system table.
	// +kubebuilder:validation:Optional
	ZookeeperLogEnabled *bool `json:"zookeeperLogEnabled,omitempty" tf:"zookeeper_log_enabled,omitempty"`

	// (Number) The maximum size that zookeeper_log can grow to before old data will be removed.
	// The maximum size that zookeeper_log can grow to before old data will be removed.
	// +kubebuilder:validation:Optional
	ZookeeperLogRetentionSize *float64 `json:"zookeeperLogRetentionSize,omitempty" tf:"zookeeper_log_retention_size,omitempty"`

	// (Number) The maximum time that zookeeper_log records will be retained before removal.
	// The maximum time that zookeeper_log records will be retained before removal.
	// +kubebuilder:validation:Optional
	ZookeeperLogRetentionTime *float64 `json:"zookeeperLogRetentionTime,omitempty" tf:"zookeeper_log_retention_time,omitempty"`
}

type ClickhouseResourcesInitParameters struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ClickhouseResourcesObservation struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ClickhouseResourcesParameters struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId" tf:"resource_preset_id,omitempty"`
}

type ConfigCompressionInitParameters struct {

	// (Number) Compression level for ZSTD method.
	// Compression level for `ZSTD` method.
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// (String) Compression method. Two methods are available: LZ4 and zstd.
	// Compression method. Two methods are available: `LZ4` and `zstd`.
	Method *string `json:"method,omitempty" tf:"method,omitempty"`

	// (Number) Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	MinPartSize *float64 `json:"minPartSize,omitempty" tf:"min_part_size,omitempty"`

	// (Number) Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	MinPartSizeRatio *float64 `json:"minPartSizeRatio,omitempty" tf:"min_part_size_ratio,omitempty"`
}

type ConfigCompressionObservation struct {

	// (Number) Compression level for ZSTD method.
	// Compression level for `ZSTD` method.
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// (String) Compression method. Two methods are available: LZ4 and zstd.
	// Compression method. Two methods are available: `LZ4` and `zstd`.
	Method *string `json:"method,omitempty" tf:"method,omitempty"`

	// (Number) Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	MinPartSize *float64 `json:"minPartSize,omitempty" tf:"min_part_size,omitempty"`

	// (Number) Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	MinPartSizeRatio *float64 `json:"minPartSizeRatio,omitempty" tf:"min_part_size_ratio,omitempty"`
}

type ConfigCompressionParameters struct {

	// (Number) Compression level for ZSTD method.
	// Compression level for `ZSTD` method.
	// +kubebuilder:validation:Optional
	Level *float64 `json:"level,omitempty" tf:"level,omitempty"`

	// (String) Compression method. Two methods are available: LZ4 and zstd.
	// Compression method. Two methods are available: `LZ4` and `zstd`.
	// +kubebuilder:validation:Optional
	Method *string `json:"method" tf:"method,omitempty"`

	// (Number) Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
	// +kubebuilder:validation:Optional
	MinPartSize *float64 `json:"minPartSize" tf:"min_part_size,omitempty"`

	// (Number) Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
	// +kubebuilder:validation:Optional
	MinPartSizeRatio *float64 `json:"minPartSizeRatio" tf:"min_part_size_ratio,omitempty"`
}

type ConfigGraphiteRollupInitParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Graphite rollup configuration name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The name of the column storing the metric name (Graphite sensor). Default value: Path.
	// The name of the column storing the metric name (Graphite sensor). Default value: Path.
	PathColumnName *string `json:"pathColumnName,omitempty" tf:"path_column_name,omitempty"`

	// (Attributes List) Set of thinning rules. (see below for nested schema)
	Patterns []PatternsInitParameters `json:"patterns,omitempty" tf:"patterns,omitempty"`

	// (String) The name of the column storing the time of measuring the metric. Default value: Time.
	// The name of the column storing the time of measuring the metric. Default value: Time.
	TimeColumnName *string `json:"timeColumnName,omitempty" tf:"time_column_name,omitempty"`

	// (String) The name of the column storing the value of the metric at the time set in time_column_name. Default value: Value.
	// The name of the column storing the value of the metric at the time set in `time_column_name`. Default value: Value.
	ValueColumnName *string `json:"valueColumnName,omitempty" tf:"value_column_name,omitempty"`

	// (String) The name of the column storing the version of the metric. Default value: Timestamp.
	// The name of the column storing the version of the metric. Default value: Timestamp.
	VersionColumnName *string `json:"versionColumnName,omitempty" tf:"version_column_name,omitempty"`
}

type ConfigGraphiteRollupObservation struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Graphite rollup configuration name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The name of the column storing the metric name (Graphite sensor). Default value: Path.
	// The name of the column storing the metric name (Graphite sensor). Default value: Path.
	PathColumnName *string `json:"pathColumnName,omitempty" tf:"path_column_name,omitempty"`

	// (Attributes List) Set of thinning rules. (see below for nested schema)
	Patterns []PatternsObservation `json:"patterns,omitempty" tf:"patterns,omitempty"`

	// (String) The name of the column storing the time of measuring the metric. Default value: Time.
	// The name of the column storing the time of measuring the metric. Default value: Time.
	TimeColumnName *string `json:"timeColumnName,omitempty" tf:"time_column_name,omitempty"`

	// (String) The name of the column storing the value of the metric at the time set in time_column_name. Default value: Value.
	// The name of the column storing the value of the metric at the time set in `time_column_name`. Default value: Value.
	ValueColumnName *string `json:"valueColumnName,omitempty" tf:"value_column_name,omitempty"`

	// (String) The name of the column storing the version of the metric. Default value: Timestamp.
	// The name of the column storing the version of the metric. Default value: Timestamp.
	VersionColumnName *string `json:"versionColumnName,omitempty" tf:"version_column_name,omitempty"`
}

type ConfigGraphiteRollupParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Graphite rollup configuration name.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (String) The name of the column storing the metric name (Graphite sensor). Default value: Path.
	// The name of the column storing the metric name (Graphite sensor). Default value: Path.
	// +kubebuilder:validation:Optional
	PathColumnName *string `json:"pathColumnName,omitempty" tf:"path_column_name,omitempty"`

	// (Attributes List) Set of thinning rules. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Patterns []PatternsParameters `json:"patterns,omitempty" tf:"patterns,omitempty"`

	// (String) The name of the column storing the time of measuring the metric. Default value: Time.
	// The name of the column storing the time of measuring the metric. Default value: Time.
	// +kubebuilder:validation:Optional
	TimeColumnName *string `json:"timeColumnName,omitempty" tf:"time_column_name,omitempty"`

	// (String) The name of the column storing the value of the metric at the time set in time_column_name. Default value: Value.
	// The name of the column storing the value of the metric at the time set in `time_column_name`. Default value: Value.
	// +kubebuilder:validation:Optional
	ValueColumnName *string `json:"valueColumnName,omitempty" tf:"value_column_name,omitempty"`

	// (String) The name of the column storing the version of the metric. Default value: Timestamp.
	// The name of the column storing the version of the metric. Default value: Timestamp.
	// +kubebuilder:validation:Optional
	VersionColumnName *string `json:"versionColumnName,omitempty" tf:"version_column_name,omitempty"`
}

type ConfigJdbcBridgeInitParameters struct {

	// (String) Host of jdbc bridge.
	// Host of jdbc bridge.
	Host *string `json:"host,omitempty" tf:"host,omitempty"`

	// (Number) Port of jdbc bridge. Default value: 9019.
	// Port of jdbc bridge. Default value: 9019.
	Port *float64 `json:"port,omitempty" tf:"port,omitempty"`
}

type ConfigJdbcBridgeObservation struct {

	// (String) Host of jdbc bridge.
	// Host of jdbc bridge.
	Host *string `json:"host,omitempty" tf:"host,omitempty"`

	// (Number) Port of jdbc bridge. Default value: 9019.
	// Port of jdbc bridge. Default value: 9019.
	Port *float64 `json:"port,omitempty" tf:"port,omitempty"`
}

type ConfigJdbcBridgeParameters struct {

	// (String) Host of jdbc bridge.
	// Host of jdbc bridge.
	// +kubebuilder:validation:Optional
	Host *string `json:"host" tf:"host,omitempty"`

	// (Number) Port of jdbc bridge. Default value: 9019.
	// Port of jdbc bridge. Default value: 9019.
	// +kubebuilder:validation:Optional
	Port *float64 `json:"port,omitempty" tf:"port,omitempty"`
}

type ConfigKafkaInitParameters struct {

	// (String) Action when no initial offset: 'smallest','earliest','largest','latest','error'.
	// Action when no initial offset: 'smallest','earliest','largest','latest','error'.
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// (Number) Maximum allowed time between calls to consume messages. If exceeded, consumer is considered failed.
	// Maximum allowed time between calls to consume messages. If exceeded, consumer is considered failed.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String, Sensitive) User password on kafka server.
	// User password on kafka server.
	SaslPasswordSecretRef *v1.LocalSecretKeySelector `json:"saslPasswordSecretRef,omitempty" tf:"-"`

	// (String) Username on kafka server.
	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout.
	// Client group session and failure detection timeout.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type ConfigKafkaObservation struct {

	// (String) Action when no initial offset: 'smallest','earliest','largest','latest','error'.
	// Action when no initial offset: 'smallest','earliest','largest','latest','error'.
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// (Number) Maximum allowed time between calls to consume messages. If exceeded, consumer is considered failed.
	// Maximum allowed time between calls to consume messages. If exceeded, consumer is considered failed.
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String) Username on kafka server.
	// Username on kafka server.
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout.
	// Client group session and failure detection timeout.
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type ConfigKafkaParameters struct {

	// (String) Action when no initial offset: 'smallest','earliest','largest','latest','error'.
	// Action when no initial offset: 'smallest','earliest','largest','latest','error'.
	// +kubebuilder:validation:Optional
	AutoOffsetReset *string `json:"autoOffsetReset,omitempty" tf:"auto_offset_reset,omitempty"`

	// separated list of debug contexts to enable.
	// A comma-separated list of debug contexts to enable.
	// +kubebuilder:validation:Optional
	Debug *string `json:"debug,omitempty" tf:"debug,omitempty"`

	// (Boolean) Enable verification of SSL certificates.
	// Enable verification of SSL certificates.
	// +kubebuilder:validation:Optional
	EnableSSLCertificateVerification *bool `json:"enableSslCertificateVerification,omitempty" tf:"enable_ssl_certificate_verification,omitempty"`

	// (Number) Maximum allowed time between calls to consume messages. If exceeded, consumer is considered failed.
	// Maximum allowed time between calls to consume messages. If exceeded, consumer is considered failed.
	// +kubebuilder:validation:Optional
	MaxPollIntervalMs *float64 `json:"maxPollIntervalMs,omitempty" tf:"max_poll_interval_ms,omitempty"`

	// (String) SASL mechanism used in kafka authentication.
	// SASL mechanism used in kafka authentication.
	// +kubebuilder:validation:Optional
	SaslMechanism *string `json:"saslMechanism,omitempty" tf:"sasl_mechanism,omitempty"`

	// (String, Sensitive) User password on kafka server.
	// User password on kafka server.
	// +kubebuilder:validation:Optional
	SaslPasswordSecretRef *v1.LocalSecretKeySelector `json:"saslPasswordSecretRef,omitempty" tf:"-"`

	// (String) Username on kafka server.
	// Username on kafka server.
	// +kubebuilder:validation:Optional
	SaslUsername *string `json:"saslUsername,omitempty" tf:"sasl_username,omitempty"`

	// (String) Security protocol used to connect to kafka server.
	// Security protocol used to connect to kafka server.
	// +kubebuilder:validation:Optional
	SecurityProtocol *string `json:"securityProtocol,omitempty" tf:"security_protocol,omitempty"`

	// (Number) Client group session and failure detection timeout.
	// Client group session and failure detection timeout.
	// +kubebuilder:validation:Optional
	SessionTimeoutMs *float64 `json:"sessionTimeoutMs,omitempty" tf:"session_timeout_ms,omitempty"`
}

type ConfigMergeTreeInitParameters struct {

	// (Boolean) Enables the check at table creation that the sampling column type is correct. Default value: true.
	// Enables the check at table creation that the sampling column type is correct. Default value: true.
	CheckSampleColumnIsCorrect *bool `json:"checkSampleColumnIsCorrect,omitempty" tf:"check_sample_column_is_correct,omitempty"`

	// (Number) Minimum period to clean old queue logs, blocks hashes and parts.
	// Minimum period to clean old queue logs, blocks hashes and parts.
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// (String) Determines the behavior of background merges for MergeTree tables with projections.
	// Determines the behavior of background merges for MergeTree tables with projections.
	DeduplicateMergeProjectionMode *string `json:"deduplicateMergeProjectionMode,omitempty" tf:"deduplicate_merge_projection_mode,omitempty"`

	// (Boolean) Do fsync for every inserted part. Significantly decreases performance of inserts, not recommended to use with wide parts.
	// Do fsync for every inserted part. Significantly decreases performance of inserts, not recommended to use with wide parts.
	FsyncAfterInsert *bool `json:"fsyncAfterInsert,omitempty" tf:"fsync_after_insert,omitempty"`

	// (Boolean) Do fsync for part directory after all part operations (writes, renames, etc.).
	// Do fsync for part directory after all part operations (writes, renames, etc.).
	FsyncPartDirectory *bool `json:"fsyncPartDirectory,omitempty" tf:"fsync_part_directory,omitempty"`

	// (Number) If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	// If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	InactivePartsToDelayInsert *float64 `json:"inactivePartsToDelayInsert,omitempty" tf:"inactive_parts_to_delay_insert,omitempty"`

	// (Number) If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts exception.
	// If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the `Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts` exception.
	InactivePartsToThrowInsert *float64 `json:"inactivePartsToThrowInsert,omitempty" tf:"inactive_parts_to_throw_insert,omitempty"`

	// (String) Determines the behavior of lightweight deletes for MergeTree tables with projections.
	// Determines the behavior of lightweight deletes for MergeTree tables with projections.
	LightweightMutationProjectionMode *string `json:"lightweightMutationProjectionMode,omitempty" tf:"lightweight_mutation_projection_mode,omitempty"`

	// (Boolean) Only recalculate ttl info when MATERIALIZE TTL.
	// Only recalculate ttl info when **MATERIALIZE TTL**.
	MaterializeTTLRecalculateOnly *bool `json:"materializeTtlRecalculateOnly,omitempty" tf:"materialize_ttl_recalculate_only,omitempty"`

	// (Number) The too many parts check will be active only if the average part size is not larger than the specified threshold. This allows large tables if parts are successfully merged.
	// The `too many parts` check will be active only if the average part size is not larger than the specified threshold. This allows large tables if parts are successfully merged.
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// (Number) The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. Roughly corresponds to the maximum possible part size created by an automatic background merge.
	// The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. Roughly corresponds to the maximum possible part size created by an automatic background merge.
	MaxBytesToMergeAtMaxSpaceInPool *float64 `json:"maxBytesToMergeAtMaxSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_max_space_in_pool,omitempty"`

	// (Number) Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// (Number) Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	// Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	MaxCleanupDelayPeriod *float64 `json:"maxCleanupDelayPeriod,omitempty" tf:"max_cleanup_delay_period,omitempty"`

	// (Number) Maximum sleep time for merge selecting. Default value: 60000 milliseconds (60 seconds).
	// Maximum sleep time for merge selecting. Default value: 60000 milliseconds (60 seconds).
	MaxMergeSelectingSleepMs *float64 `json:"maxMergeSelectingSleepMs,omitempty" tf:"max_merge_selecting_sleep_ms,omitempty"`

	// (Number) When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// (Number) Maximum number of parts in all partitions.
	// Maximum number of parts in all partitions.
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// (Number) Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// (Number) The number of rows that are read from the merged parts into memory. Default value: 8192.
	// The number of rows that are read from the merged parts into memory. Default value: 8192.
	MergeMaxBlockSize *float64 `json:"mergeMaxBlockSize,omitempty" tf:"merge_max_block_size,omitempty"`

	// (Number) Sleep time for merge selecting when no part is selected. Lower values increase ZooKeeper requests in large clusters.
	// Sleep time for merge selecting when no part is selected. Lower values increase ZooKeeper requests in large clusters.
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// (Boolean) Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// (Number) Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	// Merge parts if every part in the range is older than the value of `min_age_to_force_merge_seconds`.
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// (Number) Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// (Number) Minimal number of rows to do fsync for part after merge. 0 means disabled.
	// Minimal number of rows to do fsync for part after merge. **0** means disabled.
	MinCompressedBytesToFsyncAfterFetch *float64 `json:"minCompressedBytesToFsyncAfterFetch,omitempty" tf:"min_compressed_bytes_to_fsync_after_fetch,omitempty"`

	// (Number) Minimal number of compressed bytes to do fsync for part after merge. 0 means disabled.
	// Minimal number of compressed bytes to do fsync for part after merge. **0** means disabled.
	MinCompressedBytesToFsyncAfterMerge *float64 `json:"minCompressedBytesToFsyncAfterMerge,omitempty" tf:"min_compressed_bytes_to_fsync_after_merge,omitempty"`

	// (Number) Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// (Number) Minimal number of rows to do fsync for part after merge. 0 means disabled.
	// Minimal number of rows to do fsync for part after merge. **0** means disabled.
	MinRowsToFsyncAfterMerge *float64 `json:"minRowsToFsyncAfterMerge,omitempty" tf:"min_rows_to_fsync_after_merge,omitempty"`

	// (Number) When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid Too many parts. Default value: 20.
	// When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid `Too many parts`. Default value: 20.
	NumberOfFreeEntriesInPoolToExecuteMutation *float64 `json:"numberOfFreeEntriesInPoolToExecuteMutation,omitempty" tf:"number_of_free_entries_in_pool_to_execute_mutation,omitempty"`

	// (Number) Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// (Number) Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// (Number) Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// (Number) Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// (Number) Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones will be deleted).
	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones will be deleted).
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// copy replication when a replica is located on a remote filesystem.
	// Enables zero-copy replication when a replica is located on a remote filesystem.
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type ConfigMergeTreeObservation struct {

	// (Boolean) Enables the check at table creation that the sampling column type is correct. Default value: true.
	// Enables the check at table creation that the sampling column type is correct. Default value: true.
	CheckSampleColumnIsCorrect *bool `json:"checkSampleColumnIsCorrect,omitempty" tf:"check_sample_column_is_correct,omitempty"`

	// (Number) Minimum period to clean old queue logs, blocks hashes and parts.
	// Minimum period to clean old queue logs, blocks hashes and parts.
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// (String) Determines the behavior of background merges for MergeTree tables with projections.
	// Determines the behavior of background merges for MergeTree tables with projections.
	DeduplicateMergeProjectionMode *string `json:"deduplicateMergeProjectionMode,omitempty" tf:"deduplicate_merge_projection_mode,omitempty"`

	// (Boolean) Do fsync for every inserted part. Significantly decreases performance of inserts, not recommended to use with wide parts.
	// Do fsync for every inserted part. Significantly decreases performance of inserts, not recommended to use with wide parts.
	FsyncAfterInsert *bool `json:"fsyncAfterInsert,omitempty" tf:"fsync_after_insert,omitempty"`

	// (Boolean) Do fsync for part directory after all part operations (writes, renames, etc.).
	// Do fsync for part directory after all part operations (writes, renames, etc.).
	FsyncPartDirectory *bool `json:"fsyncPartDirectory,omitempty" tf:"fsync_part_directory,omitempty"`

	// (Number) If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	// If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	InactivePartsToDelayInsert *float64 `json:"inactivePartsToDelayInsert,omitempty" tf:"inactive_parts_to_delay_insert,omitempty"`

	// (Number) If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts exception.
	// If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the `Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts` exception.
	InactivePartsToThrowInsert *float64 `json:"inactivePartsToThrowInsert,omitempty" tf:"inactive_parts_to_throw_insert,omitempty"`

	// (String) Determines the behavior of lightweight deletes for MergeTree tables with projections.
	// Determines the behavior of lightweight deletes for MergeTree tables with projections.
	LightweightMutationProjectionMode *string `json:"lightweightMutationProjectionMode,omitempty" tf:"lightweight_mutation_projection_mode,omitempty"`

	// (Boolean) Only recalculate ttl info when MATERIALIZE TTL.
	// Only recalculate ttl info when **MATERIALIZE TTL**.
	MaterializeTTLRecalculateOnly *bool `json:"materializeTtlRecalculateOnly,omitempty" tf:"materialize_ttl_recalculate_only,omitempty"`

	// (Number) The too many parts check will be active only if the average part size is not larger than the specified threshold. This allows large tables if parts are successfully merged.
	// The `too many parts` check will be active only if the average part size is not larger than the specified threshold. This allows large tables if parts are successfully merged.
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// (Number) The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. Roughly corresponds to the maximum possible part size created by an automatic background merge.
	// The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. Roughly corresponds to the maximum possible part size created by an automatic background merge.
	MaxBytesToMergeAtMaxSpaceInPool *float64 `json:"maxBytesToMergeAtMaxSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_max_space_in_pool,omitempty"`

	// (Number) Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// (Number) Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	// Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	MaxCleanupDelayPeriod *float64 `json:"maxCleanupDelayPeriod,omitempty" tf:"max_cleanup_delay_period,omitempty"`

	// (Number) Maximum sleep time for merge selecting. Default value: 60000 milliseconds (60 seconds).
	// Maximum sleep time for merge selecting. Default value: 60000 milliseconds (60 seconds).
	MaxMergeSelectingSleepMs *float64 `json:"maxMergeSelectingSleepMs,omitempty" tf:"max_merge_selecting_sleep_ms,omitempty"`

	// (Number) When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// (Number) Maximum number of parts in all partitions.
	// Maximum number of parts in all partitions.
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// (Number) Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// (Number) The number of rows that are read from the merged parts into memory. Default value: 8192.
	// The number of rows that are read from the merged parts into memory. Default value: 8192.
	MergeMaxBlockSize *float64 `json:"mergeMaxBlockSize,omitempty" tf:"merge_max_block_size,omitempty"`

	// (Number) Sleep time for merge selecting when no part is selected. Lower values increase ZooKeeper requests in large clusters.
	// Sleep time for merge selecting when no part is selected. Lower values increase ZooKeeper requests in large clusters.
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// (Boolean) Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// (Number) Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	// Merge parts if every part in the range is older than the value of `min_age_to_force_merge_seconds`.
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// (Number) Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// (Number) Minimal number of rows to do fsync for part after merge. 0 means disabled.
	// Minimal number of rows to do fsync for part after merge. **0** means disabled.
	MinCompressedBytesToFsyncAfterFetch *float64 `json:"minCompressedBytesToFsyncAfterFetch,omitempty" tf:"min_compressed_bytes_to_fsync_after_fetch,omitempty"`

	// (Number) Minimal number of compressed bytes to do fsync for part after merge. 0 means disabled.
	// Minimal number of compressed bytes to do fsync for part after merge. **0** means disabled.
	MinCompressedBytesToFsyncAfterMerge *float64 `json:"minCompressedBytesToFsyncAfterMerge,omitempty" tf:"min_compressed_bytes_to_fsync_after_merge,omitempty"`

	// (Number) Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// (Number) Minimal number of rows to do fsync for part after merge. 0 means disabled.
	// Minimal number of rows to do fsync for part after merge. **0** means disabled.
	MinRowsToFsyncAfterMerge *float64 `json:"minRowsToFsyncAfterMerge,omitempty" tf:"min_rows_to_fsync_after_merge,omitempty"`

	// (Number) When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid Too many parts. Default value: 20.
	// When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid `Too many parts`. Default value: 20.
	NumberOfFreeEntriesInPoolToExecuteMutation *float64 `json:"numberOfFreeEntriesInPoolToExecuteMutation,omitempty" tf:"number_of_free_entries_in_pool_to_execute_mutation,omitempty"`

	// (Number) Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// (Number) Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// (Number) Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// (Number) Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// (Number) Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones will be deleted).
	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones will be deleted).
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// copy replication when a replica is located on a remote filesystem.
	// Enables zero-copy replication when a replica is located on a remote filesystem.
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type ConfigMergeTreeParameters struct {

	// (Boolean) Enables the check at table creation that the sampling column type is correct. Default value: true.
	// Enables the check at table creation that the sampling column type is correct. Default value: true.
	// +kubebuilder:validation:Optional
	CheckSampleColumnIsCorrect *bool `json:"checkSampleColumnIsCorrect,omitempty" tf:"check_sample_column_is_correct,omitempty"`

	// (Number) Minimum period to clean old queue logs, blocks hashes and parts.
	// Minimum period to clean old queue logs, blocks hashes and parts.
	// +kubebuilder:validation:Optional
	CleanupDelayPeriod *float64 `json:"cleanupDelayPeriod,omitempty" tf:"cleanup_delay_period,omitempty"`

	// (String) Determines the behavior of background merges for MergeTree tables with projections.
	// Determines the behavior of background merges for MergeTree tables with projections.
	// +kubebuilder:validation:Optional
	DeduplicateMergeProjectionMode *string `json:"deduplicateMergeProjectionMode,omitempty" tf:"deduplicate_merge_projection_mode,omitempty"`

	// (Boolean) Do fsync for every inserted part. Significantly decreases performance of inserts, not recommended to use with wide parts.
	// Do fsync for every inserted part. Significantly decreases performance of inserts, not recommended to use with wide parts.
	// +kubebuilder:validation:Optional
	FsyncAfterInsert *bool `json:"fsyncAfterInsert,omitempty" tf:"fsync_after_insert,omitempty"`

	// (Boolean) Do fsync for part directory after all part operations (writes, renames, etc.).
	// Do fsync for part directory after all part operations (writes, renames, etc.).
	// +kubebuilder:validation:Optional
	FsyncPartDirectory *bool `json:"fsyncPartDirectory,omitempty" tf:"fsync_part_directory,omitempty"`

	// (Number) If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	// If the number of inactive parts in a single partition in the table at least that many the inactive_parts_to_delay_insert value, an INSERT artificially slows down. It is useful when a server fails to clean up parts quickly enough.
	// +kubebuilder:validation:Optional
	InactivePartsToDelayInsert *float64 `json:"inactivePartsToDelayInsert,omitempty" tf:"inactive_parts_to_delay_insert,omitempty"`

	// (Number) If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts exception.
	// If the number of inactive parts in a single partition more than the inactive_parts_to_throw_insert value, INSERT is interrupted with the `Too many inactive parts (N). Parts cleaning are processing significantly slower than inserts` exception.
	// +kubebuilder:validation:Optional
	InactivePartsToThrowInsert *float64 `json:"inactivePartsToThrowInsert,omitempty" tf:"inactive_parts_to_throw_insert,omitempty"`

	// (String) Determines the behavior of lightweight deletes for MergeTree tables with projections.
	// Determines the behavior of lightweight deletes for MergeTree tables with projections.
	// +kubebuilder:validation:Optional
	LightweightMutationProjectionMode *string `json:"lightweightMutationProjectionMode,omitempty" tf:"lightweight_mutation_projection_mode,omitempty"`

	// (Boolean) Only recalculate ttl info when MATERIALIZE TTL.
	// Only recalculate ttl info when **MATERIALIZE TTL**.
	// +kubebuilder:validation:Optional
	MaterializeTTLRecalculateOnly *bool `json:"materializeTtlRecalculateOnly,omitempty" tf:"materialize_ttl_recalculate_only,omitempty"`

	// (Number) The too many parts check will be active only if the average part size is not larger than the specified threshold. This allows large tables if parts are successfully merged.
	// The `too many parts` check will be active only if the average part size is not larger than the specified threshold. This allows large tables if parts are successfully merged.
	// +kubebuilder:validation:Optional
	MaxAvgPartSizeForTooManyParts *float64 `json:"maxAvgPartSizeForTooManyParts,omitempty" tf:"max_avg_part_size_for_too_many_parts,omitempty"`

	// (Number) The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. Roughly corresponds to the maximum possible part size created by an automatic background merge.
	// The maximum total parts size (in bytes) to be merged into one part, if there are enough resources available. Roughly corresponds to the maximum possible part size created by an automatic background merge.
	// +kubebuilder:validation:Optional
	MaxBytesToMergeAtMaxSpaceInPool *float64 `json:"maxBytesToMergeAtMaxSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_max_space_in_pool,omitempty"`

	// (Number) Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
	// +kubebuilder:validation:Optional
	MaxBytesToMergeAtMinSpaceInPool *float64 `json:"maxBytesToMergeAtMinSpaceInPool,omitempty" tf:"max_bytes_to_merge_at_min_space_in_pool,omitempty"`

	// (Number) Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	// Maximum period to clean old queue logs, blocks hashes and parts. Default value: 300 seconds.
	// +kubebuilder:validation:Optional
	MaxCleanupDelayPeriod *float64 `json:"maxCleanupDelayPeriod,omitempty" tf:"max_cleanup_delay_period,omitempty"`

	// (Number) Maximum sleep time for merge selecting. Default value: 60000 milliseconds (60 seconds).
	// Maximum sleep time for merge selecting. Default value: 60000 milliseconds (60 seconds).
	// +kubebuilder:validation:Optional
	MaxMergeSelectingSleepMs *float64 `json:"maxMergeSelectingSleepMs,omitempty" tf:"max_merge_selecting_sleep_ms,omitempty"`

	// (Number) When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
	// +kubebuilder:validation:Optional
	MaxNumberOfMergesWithTTLInPool *float64 `json:"maxNumberOfMergesWithTtlInPool,omitempty" tf:"max_number_of_merges_with_ttl_in_pool,omitempty"`

	// (Number) Maximum number of parts in all partitions.
	// Maximum number of parts in all partitions.
	// +kubebuilder:validation:Optional
	MaxPartsInTotal *float64 `json:"maxPartsInTotal,omitempty" tf:"max_parts_in_total,omitempty"`

	// (Number) Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
	// +kubebuilder:validation:Optional
	MaxReplicatedMergesInQueue *float64 `json:"maxReplicatedMergesInQueue,omitempty" tf:"max_replicated_merges_in_queue,omitempty"`

	// (Number) The number of rows that are read from the merged parts into memory. Default value: 8192.
	// The number of rows that are read from the merged parts into memory. Default value: 8192.
	// +kubebuilder:validation:Optional
	MergeMaxBlockSize *float64 `json:"mergeMaxBlockSize,omitempty" tf:"merge_max_block_size,omitempty"`

	// (Number) Sleep time for merge selecting when no part is selected. Lower values increase ZooKeeper requests in large clusters.
	// Sleep time for merge selecting when no part is selected. Lower values increase ZooKeeper requests in large clusters.
	// +kubebuilder:validation:Optional
	MergeSelectingSleepMs *float64 `json:"mergeSelectingSleepMs,omitempty" tf:"merge_selecting_sleep_ms,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
	// +kubebuilder:validation:Optional
	MergeWithRecompressionTTLTimeout *float64 `json:"mergeWithRecompressionTtlTimeout,omitempty" tf:"merge_with_recompression_ttl_timeout,omitempty"`

	// (Number) Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
	// +kubebuilder:validation:Optional
	MergeWithTTLTimeout *float64 `json:"mergeWithTtlTimeout,omitempty" tf:"merge_with_ttl_timeout,omitempty"`

	// (Boolean) Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset.
	// +kubebuilder:validation:Optional
	MinAgeToForceMergeOnPartitionOnly *bool `json:"minAgeToForceMergeOnPartitionOnly,omitempty" tf:"min_age_to_force_merge_on_partition_only,omitempty"`

	// (Number) Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds.
	// Merge parts if every part in the range is older than the value of `min_age_to_force_merge_seconds`.
	// +kubebuilder:validation:Optional
	MinAgeToForceMergeSeconds *float64 `json:"minAgeToForceMergeSeconds,omitempty" tf:"min_age_to_force_merge_seconds,omitempty"`

	// (Number) Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// +kubebuilder:validation:Optional
	MinBytesForWidePart *float64 `json:"minBytesForWidePart,omitempty" tf:"min_bytes_for_wide_part,omitempty"`

	// (Number) Minimal number of rows to do fsync for part after merge. 0 means disabled.
	// Minimal number of rows to do fsync for part after merge. **0** means disabled.
	// +kubebuilder:validation:Optional
	MinCompressedBytesToFsyncAfterFetch *float64 `json:"minCompressedBytesToFsyncAfterFetch,omitempty" tf:"min_compressed_bytes_to_fsync_after_fetch,omitempty"`

	// (Number) Minimal number of compressed bytes to do fsync for part after merge. 0 means disabled.
	// Minimal number of compressed bytes to do fsync for part after merge. **0** means disabled.
	// +kubebuilder:validation:Optional
	MinCompressedBytesToFsyncAfterMerge *float64 `json:"minCompressedBytesToFsyncAfterMerge,omitempty" tf:"min_compressed_bytes_to_fsync_after_merge,omitempty"`

	// (Number) Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
	// +kubebuilder:validation:Optional
	MinRowsForWidePart *float64 `json:"minRowsForWidePart,omitempty" tf:"min_rows_for_wide_part,omitempty"`

	// (Number) Minimal number of rows to do fsync for part after merge. 0 means disabled.
	// Minimal number of rows to do fsync for part after merge. **0** means disabled.
	// +kubebuilder:validation:Optional
	MinRowsToFsyncAfterMerge *float64 `json:"minRowsToFsyncAfterMerge,omitempty" tf:"min_rows_to_fsync_after_merge,omitempty"`

	// (Number) When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid Too many parts. Default value: 20.
	// When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid `Too many parts`. Default value: 20.
	// +kubebuilder:validation:Optional
	NumberOfFreeEntriesInPoolToExecuteMutation *float64 `json:"numberOfFreeEntriesInPoolToExecuteMutation,omitempty" tf:"number_of_free_entries_in_pool_to_execute_mutation,omitempty"`

	// (Number) Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
	// +kubebuilder:validation:Optional
	NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge *float64 `json:"numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,omitempty" tf:"number_of_free_entries_in_pool_to_lower_max_size_of_merge,omitempty"`

	// (Number) Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table
	// +kubebuilder:validation:Optional
	PartsToDelayInsert *float64 `json:"partsToDelayInsert,omitempty" tf:"parts_to_delay_insert,omitempty"`

	// (Number) Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
	// +kubebuilder:validation:Optional
	PartsToThrowInsert *float64 `json:"partsToThrowInsert,omitempty" tf:"parts_to_throw_insert,omitempty"`

	// (Number) Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
	// +kubebuilder:validation:Optional
	ReplicatedDeduplicationWindow *float64 `json:"replicatedDeduplicationWindow,omitempty" tf:"replicated_deduplication_window,omitempty"`

	// (Number) Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones will be deleted).
	// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones will be deleted).
	// +kubebuilder:validation:Optional
	ReplicatedDeduplicationWindowSeconds *float64 `json:"replicatedDeduplicationWindowSeconds,omitempty" tf:"replicated_deduplication_window_seconds,omitempty"`

	// copy replication when a replica is located on a remote filesystem.
	// Enables zero-copy replication when a replica is located on a remote filesystem.
	// +kubebuilder:validation:Optional
	TTLOnlyDropParts *bool `json:"ttlOnlyDropParts,omitempty" tf:"ttl_only_drop_parts,omitempty"`
}

type ConfigQueryCacheInitParameters struct {

	// (Number) The maximum number of SELECT query results stored in the cache. Default value: 1024.
	// The maximum number of SELECT query results stored in the cache. Default value: 1024.
	MaxEntries *float64 `json:"maxEntries,omitempty" tf:"max_entries,omitempty"`

	// (Number) The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	// The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	MaxEntrySizeInBytes *float64 `json:"maxEntrySizeInBytes,omitempty" tf:"max_entry_size_in_bytes,omitempty"`

	// (Number) The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	// The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	MaxEntrySizeInRows *float64 `json:"maxEntrySizeInRows,omitempty" tf:"max_entry_size_in_rows,omitempty"`

	// (Number) The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	// The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	MaxSizeInBytes *float64 `json:"maxSizeInBytes,omitempty" tf:"max_size_in_bytes,omitempty"`
}

type ConfigQueryCacheObservation struct {

	// (Number) The maximum number of SELECT query results stored in the cache. Default value: 1024.
	// The maximum number of SELECT query results stored in the cache. Default value: 1024.
	MaxEntries *float64 `json:"maxEntries,omitempty" tf:"max_entries,omitempty"`

	// (Number) The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	// The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	MaxEntrySizeInBytes *float64 `json:"maxEntrySizeInBytes,omitempty" tf:"max_entry_size_in_bytes,omitempty"`

	// (Number) The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	// The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	MaxEntrySizeInRows *float64 `json:"maxEntrySizeInRows,omitempty" tf:"max_entry_size_in_rows,omitempty"`

	// (Number) The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	// The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	MaxSizeInBytes *float64 `json:"maxSizeInBytes,omitempty" tf:"max_size_in_bytes,omitempty"`
}

type ConfigQueryCacheParameters struct {

	// (Number) The maximum number of SELECT query results stored in the cache. Default value: 1024.
	// The maximum number of SELECT query results stored in the cache. Default value: 1024.
	// +kubebuilder:validation:Optional
	MaxEntries *float64 `json:"maxEntries,omitempty" tf:"max_entries,omitempty"`

	// (Number) The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	// The maximum size in bytes SELECT query results may have to be saved in the cache. Default value: 1048576 (1 MiB).
	// +kubebuilder:validation:Optional
	MaxEntrySizeInBytes *float64 `json:"maxEntrySizeInBytes,omitempty" tf:"max_entry_size_in_bytes,omitempty"`

	// (Number) The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	// The maximum number of rows SELECT query results may have to be saved in the cache. Default value: 30000000 (30 mil).
	// +kubebuilder:validation:Optional
	MaxEntrySizeInRows *float64 `json:"maxEntrySizeInRows,omitempty" tf:"max_entry_size_in_rows,omitempty"`

	// (Number) The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	// The maximum cache size in bytes. 0 means the query cache is disabled. Default value: 1073741824 (1 GiB).
	// +kubebuilder:validation:Optional
	MaxSizeInBytes *float64 `json:"maxSizeInBytes,omitempty" tf:"max_size_in_bytes,omitempty"`
}

type ConfigQueryMaskingRulesInitParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name for the rule.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) Regular expression that the metric name must match.
	// RE2 compatible regular expression.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (String) Substitution string for sensitive data. Default value: six asterisks.
	// Substitution string for sensitive data. Default value: six asterisks.
	Replace *string `json:"replace,omitempty" tf:"replace,omitempty"`
}

type ConfigQueryMaskingRulesObservation struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name for the rule.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) Regular expression that the metric name must match.
	// RE2 compatible regular expression.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (String) Substitution string for sensitive data. Default value: six asterisks.
	// Substitution string for sensitive data. Default value: six asterisks.
	Replace *string `json:"replace,omitempty" tf:"replace,omitempty"`
}

type ConfigQueryMaskingRulesParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name for the rule.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) Regular expression that the metric name must match.
	// RE2 compatible regular expression.
	// +kubebuilder:validation:Optional
	Regexp *string `json:"regexp" tf:"regexp,omitempty"`

	// (String) Substitution string for sensitive data. Default value: six asterisks.
	// Substitution string for sensitive data. Default value: six asterisks.
	// +kubebuilder:validation:Optional
	Replace *string `json:"replace,omitempty" tf:"replace,omitempty"`
}

type ConfigRabbitmqInitParameters struct {

	// (String, Sensitive) RabbitMQ user password.
	// RabbitMQ user password.
	PasswordSecretRef *v1.LocalSecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// (String) RabbitMQ username.
	// RabbitMQ username.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// (String) RabbitMQ vhost. Default: \.
	// RabbitMQ vhost. Default: `\`.
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type ConfigRabbitmqObservation struct {

	// (String) RabbitMQ username.
	// RabbitMQ username.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// (String) RabbitMQ vhost. Default: \.
	// RabbitMQ vhost. Default: `\`.
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type ConfigRabbitmqParameters struct {

	// (String, Sensitive) RabbitMQ user password.
	// RabbitMQ user password.
	// +kubebuilder:validation:Optional
	PasswordSecretRef *v1.LocalSecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// (String) RabbitMQ username.
	// RabbitMQ username.
	// +kubebuilder:validation:Optional
	Username *string `json:"username,omitempty" tf:"username,omitempty"`

	// (String) RabbitMQ vhost. Default: \.
	// RabbitMQ vhost. Default: `\`.
	// +kubebuilder:validation:Optional
	Vhost *string `json:"vhost,omitempty" tf:"vhost,omitempty"`
}

type CustomMacrosInitParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name of the macro.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) Value of the macro.
	// Value of the macro.
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type CustomMacrosObservation struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name of the macro.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) Value of the macro.
	// Value of the macro.
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type CustomMacrosParameters struct {

	// (String) Name of the ClickHouse cluster. Provided by the client when the cluster is created.
	// Name of the macro.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`

	// (String) Value of the macro.
	// Value of the macro.
	// +kubebuilder:validation:Optional
	Value *string `json:"value" tf:"value,omitempty"`
}

type HostsInitParameters struct {

	// (Boolean) Whether the host should get a public IP address.
	// Whether the host should get a public IP address.
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// (String) The name of the shard to which the host belongs.
	// The name of the shard to which the host belongs.
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// (String) ID of the subnet where the host is located.
	// ID of the subnet where the host is located.
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// The type of the host to be deployed. Can be either `CLICKHOUSE` or `ZOOKEEPER`.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) The availability zone where resource is located. If it is not provided, the default provider zone will be used.
	// The [availability zone](https://yandex.cloud/docs/overview/concepts/geo-scope) where resource is located. If it is not provided, the default provider zone will be used.
	Zone *string `json:"zone,omitempty" tf:"zone,omitempty"`
}

type HostsObservation struct {

	// (Boolean) Whether the host should get a public IP address.
	// Whether the host should get a public IP address.
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// (String) The fully qualified domain name of the host.
	// The fully qualified domain name of the host.
	Fqdn *string `json:"fqdn,omitempty" tf:"fqdn,omitempty"`

	// (String) The name of the shard to which the host belongs.
	// The name of the shard to which the host belongs.
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// (String) ID of the subnet where the host is located.
	// ID of the subnet where the host is located.
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// The type of the host to be deployed. Can be either `CLICKHOUSE` or `ZOOKEEPER`.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`

	// (String) The availability zone where resource is located. If it is not provided, the default provider zone will be used.
	// The [availability zone](https://yandex.cloud/docs/overview/concepts/geo-scope) where resource is located. If it is not provided, the default provider zone will be used.
	Zone *string `json:"zone,omitempty" tf:"zone,omitempty"`
}

type HostsParameters struct {

	// (Boolean) Whether the host should get a public IP address.
	// Whether the host should get a public IP address.
	// +kubebuilder:validation:Optional
	AssignPublicIP *bool `json:"assignPublicIp,omitempty" tf:"assign_public_ip,omitempty"`

	// (String) The name of the shard to which the host belongs.
	// The name of the shard to which the host belongs.
	// +kubebuilder:validation:Optional
	ShardName *string `json:"shardName,omitempty" tf:"shard_name,omitempty"`

	// (String) ID of the subnet where the host is located.
	// ID of the subnet where the host is located.
	// +kubebuilder:validation:Optional
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// (String) The type of the host to be deployed. Can be either CLICKHOUSE or ZOOKEEPER.
	// The type of the host to be deployed. Can be either `CLICKHOUSE` or `ZOOKEEPER`.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`

	// (String) The availability zone where resource is located. If it is not provided, the default provider zone will be used.
	// The [availability zone](https://yandex.cloud/docs/overview/concepts/geo-scope) where resource is located. If it is not provided, the default provider zone will be used.
	// +kubebuilder:validation:Optional
	Zone *string `json:"zone" tf:"zone,omitempty"`
}

type PatternsInitParameters struct {

	// (String) Aggregation function name.
	// Aggregation function name.
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (String) Regular expression that the metric name must match.
	// Regular expression that the metric name must match.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (Attributes List) Retain parameters. (see below for nested schema)
	Retention []PatternsRetentionInitParameters `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PatternsObservation struct {

	// (String) Aggregation function name.
	// Aggregation function name.
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (String) Regular expression that the metric name must match.
	// Regular expression that the metric name must match.
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (Attributes List) Retain parameters. (see below for nested schema)
	Retention []PatternsRetentionObservation `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PatternsParameters struct {

	// (String) Aggregation function name.
	// Aggregation function name.
	// +kubebuilder:validation:Optional
	Function *string `json:"function" tf:"function,omitempty"`

	// (String) Regular expression that the metric name must match.
	// Regular expression that the metric name must match.
	// +kubebuilder:validation:Optional
	Regexp *string `json:"regexp,omitempty" tf:"regexp,omitempty"`

	// (Attributes List) Retain parameters. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Retention []PatternsRetentionParameters `json:"retention,omitempty" tf:"retention,omitempty"`
}

type PatternsRetentionInitParameters struct {

	// (Number) Minimum data age in seconds.
	// Minimum data age in seconds.
	Age *float64 `json:"age,omitempty" tf:"age,omitempty"`

	// (Number) Accuracy of determining the age of the data in seconds.
	// Accuracy of determining the age of the data in seconds.
	Precision *float64 `json:"precision,omitempty" tf:"precision,omitempty"`
}

type PatternsRetentionObservation struct {

	// (Number) Minimum data age in seconds.
	// Minimum data age in seconds.
	Age *float64 `json:"age,omitempty" tf:"age,omitempty"`

	// (Number) Accuracy of determining the age of the data in seconds.
	// Accuracy of determining the age of the data in seconds.
	Precision *float64 `json:"precision,omitempty" tf:"precision,omitempty"`
}

type PatternsRetentionParameters struct {

	// (Number) Minimum data age in seconds.
	// Minimum data age in seconds.
	// +kubebuilder:validation:Optional
	Age *float64 `json:"age" tf:"age,omitempty"`

	// (Number) Accuracy of determining the age of the data in seconds.
	// Accuracy of determining the age of the data in seconds.
	// +kubebuilder:validation:Optional
	Precision *float64 `json:"precision" tf:"precision,omitempty"`
}

type ShardsInitParameters struct {

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	Resources *ShardsResourcesInitParameters `json:"resources,omitempty" tf:"resources,omitempty"`

	// (Number) The weight of shard.
	// The weight of shard.
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardsObservation struct {

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	Resources *ShardsResourcesObservation `json:"resources,omitempty" tf:"resources,omitempty"`

	// (Number) The weight of shard.
	// The weight of shard.
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardsParameters struct {

	// (Attributes) Resources allocated to hosts. (see below for nested schema)
	// +kubebuilder:validation:Optional
	Resources *ShardsResourcesParameters `json:"resources,omitempty" tf:"resources,omitempty"`

	// (Number) The weight of shard.
	// The weight of shard.
	// +kubebuilder:validation:Optional
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ShardsResourcesInitParameters struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ShardsResourcesObservation struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type ShardsResourcesParameters struct {

	// (Number) Volume of the storage available to a host, in gigabytes.
	// Volume of the storage available to a host, in gigabytes.
	// +kubebuilder:validation:Optional
	DiskSize *float64 `json:"diskSize,omitempty" tf:"disk_size,omitempty"`

	// (String) Type of the storage of hosts. For more information see the official documentation.
	// Type of the storage of hosts. For more information see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts/storage).
	// +kubebuilder:validation:Optional
	DiskTypeID *string `json:"diskTypeId,omitempty" tf:"disk_type_id,omitempty"`

	// (String) The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see the official documentation.
	// The ID of the preset for computational resources available to a host (CPU, memory etc.). For more information, see [the official documentation](https://yandex.cloud/docs/managed-clickhouse/concepts).
	// +kubebuilder:validation:Optional
	ResourcePresetID *string `json:"resourcePresetId,omitempty" tf:"resource_preset_id,omitempty"`
}

type TimeoutsInitParameters struct {

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	Create *string `json:"create,omitempty" tf:"create,omitempty"`

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
	Delete *string `json:"delete,omitempty" tf:"delete,omitempty"`

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	Update *string `json:"update,omitempty" tf:"update,omitempty"`
}

type TimeoutsObservation struct {

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	Create *string `json:"create,omitempty" tf:"create,omitempty"`

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
	Delete *string `json:"delete,omitempty" tf:"delete,omitempty"`

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	Update *string `json:"update,omitempty" tf:"update,omitempty"`
}

type TimeoutsParameters struct {

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	// +kubebuilder:validation:Optional
	Create *string `json:"create,omitempty" tf:"create,omitempty"`

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
	// +kubebuilder:validation:Optional
	Delete *string `json:"delete,omitempty" tf:"delete,omitempty"`

	// (String) A string that can be parsed as a duration consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	// A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
	// +kubebuilder:validation:Optional
	Update *string `json:"update,omitempty" tf:"update,omitempty"`
}

// ClickhouseClusterV2Spec defines the desired state of ClickhouseClusterV2
type ClickhouseClusterV2Spec struct {
	v2.ManagedResourceSpec `json:",inline"`
	ForProvider            ClickhouseClusterV2Parameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider ClickhouseClusterV2InitParameters `json:"initProvider,omitempty"`
}

// ClickhouseClusterV2Status defines the observed state of ClickhouseClusterV2.
type ClickhouseClusterV2Status struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        ClickhouseClusterV2Observation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// ClickhouseClusterV2 is the Schema for the ClickhouseClusterV2s API. Manages a ClickHouse cluster within Yandex Cloud.
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Namespaced,categories={crossplane,managed,yandex-cloud}
type ClickhouseClusterV2 struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.environment) || (has(self.initProvider) && has(self.initProvider.environment))",message="spec.forProvider.environment is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.hosts) || (has(self.initProvider) && has(self.initProvider.hosts))",message="spec.forProvider.hosts is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.name) || (has(self.initProvider) && has(self.initProvider.name))",message="spec.forProvider.name is a required parameter"
	Spec   ClickhouseClusterV2Spec   `json:"spec"`
	Status ClickhouseClusterV2Status `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// ClickhouseClusterV2List contains a list of ClickhouseClusterV2s
type ClickhouseClusterV2List struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []ClickhouseClusterV2 `json:"items"`
}

// Repository type metadata.
var (
	ClickhouseClusterV2_Kind             = "ClickhouseClusterV2"
	ClickhouseClusterV2_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: ClickhouseClusterV2_Kind}.String()
	ClickhouseClusterV2_KindAPIVersion   = ClickhouseClusterV2_Kind + "." + CRDGroupVersion.String()
	ClickhouseClusterV2_GroupVersionKind = CRDGroupVersion.WithKind(ClickhouseClusterV2_Kind)
)

func init() {
	SchemeBuilder.Register(&ClickhouseClusterV2{}, &ClickhouseClusterV2List{})
}
